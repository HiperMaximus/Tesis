{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra/kaggle/input/UBC-OCEAN/test_thumbnails/41_thumbnail.png\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#os.chdir('/kaggle/input/UBC-OCEAN')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T05:35:29.454887Z","iopub.execute_input":"2024-06-10T05:35:29.455221Z","iopub.status.idle":"2024-06-10T05:35:29.919736Z","shell.execute_reply.started":"2024-06-10T05:35:29.455191Z","shell.execute_reply":"2024-06-10T05:35:29.918600Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"os.listdir()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\n\nfrom numba import jit,njit,prange\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-06-10T05:36:34.528161Z","iopub.execute_input":"2024-06-10T05:36:34.528780Z","iopub.status.idle":"2024-06-10T05:36:37.978829Z","shell.execute_reply.started":"2024-06-10T05:36:34.528729Z","shell.execute_reply":"2024-06-10T05:36:37.977750Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tiatoolbox.tools.tissuemask import MorphologicalMasker\nfrom tiatoolbox.wsicore.wsireader import WSIReader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tiatoolbox\ntiatoolbox.utils.misc.objective_power2mpp(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wsi = WSIReader.open(\"/kaggle/input/UBC-OCEAN/test_thumbnails/41_thumbnail.png\",power=20)\nbg=np.sum(wsi.img,axis=-1)==0\n#wsi.img=wsi.img/255\n#wsi.img[bg]=np.nan\nmasker = MorphologicalMasker(power=20,)\nmasks = masker.fit_transform([wsi.img])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bg=np.sum(wsi.img,axis=-1)==0\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path='/kaggle/input/UBC-OCEAN/test_thumbnails/41_thumbnail.png'\nimg=plt.imread(path)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T05:36:39.983418Z","iopub.execute_input":"2024-06-10T05:36:39.984105Z","iopub.status.idle":"2024-06-10T05:36:40.279376Z","shell.execute_reply.started":"2024-06-10T05:36:39.984067Z","shell.execute_reply":"2024-06-10T05:36:40.278110Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#@njit(parallel = True,fastmath = True,)\n@njit(parallel = True,fastmath = True,nogil=True)\ndef fill_img(img):\n    bg=np.sum(img,axis=-1)==0\n    \n    x_bg,y_bg=np.nonzero(bg)\n    x_fg,y_fg=np.nonzero(~bg)\n    \n    for i in prange(x_bg.shape[0]):\n        m=np.abs(x_fg-x_bg[i]) + np.abs(y_fg-y_bg[i])\n        m=np.argmin(m)\n        img[x_bg[i],y_bg[i],:]=img[x_fg[m],y_fg[m],:]\n    return img","metadata":{"execution":{"iopub.status.busy":"2024-06-10T05:36:44.504192Z","iopub.execute_input":"2024-06-10T05:36:44.504732Z","iopub.status.idle":"2024-06-10T05:36:44.525067Z","shell.execute_reply.started":"2024-06-10T05:36:44.504693Z","shell.execute_reply":"2024-06-10T05:36:44.523203Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"t=fill_img(img)\nt","metadata":{"execution":{"iopub.status.busy":"2024-06-10T05:36:55.760561Z","iopub.execute_input":"2024-06-10T05:36:55.761019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t.size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t[0].size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img=np.zeros(img.shape)\ntest_img[idx_fg[545337]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path='/kaggle/input/UBC-OCEAN/test_thumbnails/41_thumbnail.png'\nimg=plt.imread(path)\nbg=np.sum(img,axis=-1)==0\n\nvertical,horizontal=bg.shape\nvertical,horizontal=vertical//128,horizontal//128\n\nimg=img[:vertical,:horizontal]\n\ntest_img=np.zeros(img.shape,dtype=int,)\nplt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path='/kaggle/input/UBC-OCEAN/test_thumbnails/41_thumbnail.png'\nimg=plt.imread(path)\n\n\nplt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bg.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"3000-((3000//128)*128)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m=masks[0][8493-500:8493+500,14234-500:14234+500]\nplt.imshow(m)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(wsi.img[8493-500:8493+500,14234-500:14234+500])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thumbnail = wsi.slide_thumbnail(,)\nmasker = MorphologicalMasker()\nmasks = masker.fit_transform([thumbnail])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path='/kaggle/input/UBC-OCEAN/train_thumbnails/10077_thumbnail.png'\nwsi = WSIReader.open(input_img=img_path)\nmasker = MorphologicalMasker(power=mag_power)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Paso 1:\ngenerar parches de 128x128\nparche_id_imagen_coordenadaX_coordenadaY\n### Paso 2:\nsplit train-validation-test\nningun id_imagen puede solaparse entre train, validation o test\n### Paso 3:\nproceder a realizar el entrenamiento\nhacer monitoreo de la funcion de costo por cada epoca en train y validation\ngenerar figura con evolucion de la funcion de costo\n### Paso 4:\nseleccionar el mejor modelo con la mejor validacion\ngenerar proceso de reconstruccion con las imagenes de test\ncalcular la perdida con los parches de test\ngenerar diagramas de caja con los resultados\n### Paso 5:\nrepetir el proceso para los otros modelos: equivarianza color y equivarianza geometrica","metadata":{}},{"cell_type":"code","source":"a=plt.imread('/kaggle/input/UBC-OCEAN/test_thumbnails/41_thumbnail.png')\nplt.imshow(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        # Encoder\n        self.fc1 = nn.Linear(784, 400)\n        self.fc21 = nn.Linear(400, 20)  # mean\n        self.fc22 = nn.Linear(400, 20)  # log-variance\n\n        # Decoder\n        self.fc3 = nn.Linear(20, 400)\n        self.fc4 = nn.Linear(400, 784)\n\n    def encode(self, x):\n        h1 = F.relu(self.fc1(x))\n        return self.fc21(h1), self.fc22(h1)\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z):\n        h3 = F.relu(self.fc3(z))\n        return torch.sigmoid(self.fc4(h3))\n\n    def forward(self, x):\n        mu, logvar = self.encode(x.view(-1, 784))\n        z = self.reparameterize(mu, logvar)\n        return self.decode(z), mu, logvar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_function(recon_x, x, mu, logvar):\n    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    return BCE + KLD\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\ntransform = transforms.ToTensor()\ntrain_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n\n# Initialize the model, optimizer and loss function\nmodel = VAE()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# Training loop\nepochs = 10\nfor epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    for batch_idx, (data, _) in enumerate(train_loader):\n        data = data.to(torch.device('cpu'))\n        optimizer.zero_grad()\n        recon_batch, mu, logvar = model(data)\n        loss = loss_function(recon_batch, data, mu, logvar)\n        loss.backward()\n        train_loss += loss.item()\n        optimizer.step()\n    \n    print(f'Epoch {epoch+1}, Loss: {train_loss / len(train_loader.dataset)}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    z = torch.randn(64, 20).to(torch.device('cpu'))\n    sample = model.decode(z).cpu()\n    # Convert to images and visualize, e.g., using matplotlib\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\n\n# Create data loaders.\ntrain_dataloader = DataLoader(, batch_size=batch_size)\n\nfor X, y in train_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get cpu, gpu or mps device for training.\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder=nn.Sequential(\n            nn.Conv2d(in_channels=3,out_channels=128,kernel_size=3),#-2\n            nn.LeakyReLU(),\n            nn.MaxPool2d(3)#-np.floor(((x-3)/3)+1)\n            nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3),#-2\n            nn.LeakyReLU(),\n            nn.MaxPool2d(3),#-np.floor(((x-3)/3)+1)\n            nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3),#-2\n            nn.LeakyReLU(),\n            nn.MaxPool2d(3),#-np.floor(((x-3)/3)+1)\n            nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3),#-2\n            nn.LeakyReLU(),\n            nn.MaxPool2d(3),#-np.floor(((x-3)/3)+1)\n            nn.Conv2d(in_channels=16,out_channels=1,kernel_size=3),#-2\n            nn.LeakyReLU(),\n            nn.MaxPool2d(3),#-np.floor(((x-3)/3)+1)\n        )#(11,11,1)\n        self.feature_generation=nn.Sequential(\n            nn.Linear(11*11*1,64),\n            nn.LeakyReLU(),\n            nn.Linear(32,32),\n            nn.LeakyReLU(),\n            nn.Linear(32,32),\n            nn.LeakyReLU()\n        )\n        self.decoder=nn.Sequential(\n            nn.Linear(16,64),\n            nn.LeakyReLU(),\n            nn.Linear(64,12*12),\n            nn.LeakyReLU(),\n            nn.Unflatten(1, (12 12, 1))\n            nn.MaxUnpool2d(3),#((x-1)*3)+3\n            nn.LeakyReLU(),\n            nn.ConvTransposed2d(1,16),#+2\n            nn.MaxUnpool2d(3),#((x-1)*3)+3\n            nn.LeakyReLU(),\n            nn.ConvTransposed2d(16,32),#+2\n            nn.MaxUnpool2d(3),#((x-1)*3)+3\n            nn.LeakyReLU(),\n            nn.ConvTransposed2d(32,64),#+2\n            nn.MaxUnpool2d(3),#((x-1)*3)+3\n            nn.LeakyReLU(),\n            nn.ConvTransposed2d(64,128),#+2\n            nn.MaxUnpool2d(3),#((x-1)*3)+3\n            nn.LeakyReLU(),\n            nn.ConvTransposed2d(128,3),#+2\n        )#(3158,3158,3)\n    def forward(self, x):\n        x = self.encoder(x)\n        x = torch.flatten(x)\n        x = self.feature_generation(x)\n        mean, variance=x[:,:16],x[:,16:]\n        \n        error=torch.normal(0,1,size=16)\n        x=mean + variance*error\n        \n        x=self.decoder(x)\n        return x\n\nmodel = NeuralNetwork().to(device)\nprint(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v=\nf=lambda x:np.floo..r(((x-3)/3)+1)\nn=10\nfor _ in range(10-1):\n    print(v)\n    v=f(v)\nv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v=12\nf=lambda x:((x-1)*3)+3+2\nn=10\nfor _ in range(10-1):\n    print(v)\n    v=f(v)\nv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sizes=[]\nf='/kaggle/input/UBC-OCEAN/train_thumbnails/'\nfor a in os.listdir(f):\n    im=plt.imread(f+a)\n    \n    sizes.append()\nset(sizes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}