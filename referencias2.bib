
@inproceedings{franzen_general_2021,
	title = {General Nonlinearities in {SO}(2)-Equivariant {CNNs}},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/4bfbd52f4e8466dc12aaf30b7e057b66-Abstract.html},
	abstract = {Invariance under symmetry is an important problem in machine learning. Our paper looks specifically at equivariant neural networks where transformations of inputs yield homomorphic transformations of outputs. Here, steerable {CNNs} have emerged as the standard solution. An inherent problem of steerable representations is that general nonlinear layers break equivariance, thus restricting architectural choices. Our paper applies harmonic distortion analysis to illuminate the effect of nonlinearities on Fourier representations of {SO}(2). We develop a novel {FFT}-based algorithm for computing representations of non-linearly transformed activations while maintaining band-limitation. It yields exact equivariance for polynomial (approximations of) nonlinearities, as well as approximate solutions with tunable accuracy for general functions. We apply the approach to build a fully E(3)-equivariant network for sampled 3D surface data. In experiments with 2D and 3D data, we obtain results that compare favorably to the state-of-the-art in terms of accuracy while permitting continuous symmetry and exact equivariance.},
	pages = {9086--9098},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Franzen, Daniel and Wand, Michael},
	urldate = {2023-10-08},
	date = {2021},
	file = {Full Text PDF:/home/maxi/Zotero/storage/UBQ9WWRF/Franzen and Wand - 2021 - General Nonlinearities in SO(2)-Equivariant CNNs.pdf:application/pdf},
}

@inproceedings{shutty_computing_2022,
	title = {Computing Representations for Lie Algebraic Networks},
	url = {https://openreview.net/forum?id=Ag8HcNFfDsg&referrer=%5Bthe%20profile%20of%20Noah%20Shutty%5D(%2Fprofile%3Fid%3D~Noah_Shutty1)},
	abstract = {Recent work has constructed neural networks that are equivariant to continuous symmetry groups such as 2D and 3D rotations. This is accomplished using explicit Lie group representations to derive the equivariant kernels and nonlinearities. We present three contributions motivated by frontier applications of equivariance beyond rotations and translations. First, we relax the requirement for explicit Lie group representations with a novel algorithm that finds representations of arbitrary Lie groups given only the structure constants of the associated Lie algebra. Second, we provide a self-contained method and software for building Lie group-equivariant neural networks using these representations. Third, we contribute a novel benchmark dataset for classifying objects from relativistic point clouds, and apply our methods to construct the first object-tracking model equivariant to the Poincaré group.},
	eventtitle = {{NeurIPS} 2022 Workshop on Symmetry and Geometry in Neural Representations},
	author = {Shutty, Noah and Wierzynski, Casimir},
	urldate = {2023-10-08},
	date = {2022-11-07},
	langid = {english},
	file = {Full Text PDF:/home/maxi/Zotero/storage/3RZG3EAU/Shutty and Wierzynski - 2022 - Computing Representations for Lie Algebraic Networ.pdf:application/pdf},
}

@thesis{cohen_equivariant_2021,
	location = {Informatics Institute ({IVI})},
	title = {Equivariant convolutional networks},
	url = {https://dare.uva.nl/search?identifier=0f7014ae-ee94-430e-a5d8-37d03d8d10e6},
	abstract = {Deep neural networks can solve many kinds of learning problems, but only if a lot of data is available. For many problems (e.g. in medical imaging), it is expensive to acquire a large amount of labelled data, so it would be highly desirable to improve the statistical efficiency of deep learning methods. In this thesis we explore ways to leverage symmetries to improve the ability of convolutional neural networks to generalize from relatively small samples.
We argue and show empirically that in the context of deep learning it is better to learn equivariant rather than invariant representations, because invariant ones lose information too early on in the network. We present a sequence of increasingly general group equivariant convolutional neural networks (G-{CNNs}), adapted to the particular symmetries of various spaces. Specifically, we present roto-translation equivariant networks for planar images and volumetric signals, rotation equivariant spherical {CNNs} for analyzing spherical signals such as global weather patterns and omnidirectional images, and gauge equivariant {CNNs} for the analysis of signals on general manifolds.
We have evaluated these networks on problems such as image classification and segmentation in vision and medical imaging, 3D model classification, detection of extreme weather events, quantum chemistry, and protein structure classification. We show that across the board, G-{CNNs} outperform conventional translation equivariant {CNNs} on problems that exhibit symmetries.
In Part {II} we present a general mathematical theory of G-{CNNs}. The theory describes convolutional feature spaces as spaces of fields over a manifold, i.e. spaces of sections of an associated vector bundle. Symmetries are described as groups acting on a principal bundle by automorphisms, and layers of the network are described as linear and non-linear equivariant maps between spaces of fields. Through the use of a common mathematical language, an analogy to theoretical physics (especially gauge theory) is established. We show that in general, convolution-like maps arise from symmetry principles, and specifically that each one of the generalized convolutions used in Part I is recovered from symmetry principles as the most general class of linear maps that is equivariant to a certain group of symmetries.},
	pagetotal = {233},
	institution = {University of Amsterdam},
	type = {phdthesis},
	author = {Cohen, T. S.},
	urldate = {2023-10-08},
	date = {2021},
	langid = {english},
	file = {Full Text PDF:/home/maxi/Zotero/storage/U8GH5DSJ/Cohen - 2021 - Equivariant convolutional networks.pdf:application/pdf},
}

@online{noauthor_230518415_nodate,
	title = {[2305.18415] Geometric Algebra Transformers},
	url = {https://arxiv.org/abs/2305.18415},
	urldate = {2023-10-08},
}

@online{noauthor_220709453_nodate,
	title = {[2207.09453] e3nn: Euclidean Neural Networks},
	url = {https://arxiv.org/abs/2207.09453},
	urldate = {2023-10-08},
	file = {[2207.09453] e3nn\: Euclidean Neural Networks:/home/maxi/Zotero/storage/X9DR4WZA/2207.html:text/html},
}

@online{noauthor_230504431_nodate,
	title = {[2305.04431] Lie Group Algebra Convolutional Filters},
	url = {https://arxiv.org/abs/2305.04431},
	urldate = {2023-10-08},
	file = {[2305.04431] Lie Group Algebra Convolutional Filters:/home/maxi/Zotero/storage/FWPH6IAI/2305.html:text/html},
}

@online{noauthor_221112786_nodate,
	title = {[2211.12786] Nonlinear Equivariant Imaging: Learning Multi-Parametric Tissue Mapping without Ground Truth for Compressive Quantitative {MRI}},
	url = {https://arxiv.org/abs/2211.12786},
	urldate = {2023-10-09},
	file = {[2211.12786] Nonlinear Equivariant Imaging\: Learning Multi-Parametric Tissue Mapping without Ground Truth for Compressive Quantitative MRI:/home/maxi/Zotero/storage/B7J3G7HN/2211.html:text/html},
}

@article{glocker_risk_2023,
	title = {Risk of Bias in Chest Radiography Deep Learning Foundation Models},
	volume = {5},
	issn = {2638-6100},
	url = {http://pubs.rsna.org/doi/10.1148/ryai.230060},
	doi = {10.1148/ryai.230060},
	pages = {e230060},
	number = {6},
	journaltitle = {Radiology: Artificial Intelligence},
	shortjournal = {Radiology: Artificial Intelligence},
	author = {Glocker, Ben and Jones, Charles and Roschewitz, Mélanie and Winzeck, Stefan},
	urldate = {2023-11-04},
	date = {2023-11-01},
	langid = {english},
	file = {Versión enviada:/home/maxi/Zotero/storage/XWUXDLA2/Glocker et al. - 2023 - Risk of Bias in Chest Radiography Deep Learning Fo.pdf:application/pdf},
}

@article{hu_state---art_2023,
	title = {A state-of-the-art survey of artificial neural networks for Whole-slide Image analysis: From popular Convolutional Neural Networks to potential visual transformers},
	volume = {161},
	issn = {00104825},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010482523004997},
	doi = {10.1016/j.compbiomed.2023.107034},
	shorttitle = {A state-of-the-art survey of artificial neural networks for Whole-slide Image analysis},
	pages = {107034},
	journaltitle = {Computers in Biology and Medicine},
	shortjournal = {Computers in Biology and Medicine},
	author = {Hu, Weiming and Li, Xintong and Li, Chen and Li, Rui and Jiang, Tao and Sun, Hongzan and Huang, Xinyu and Grzegorzek, Marcin and Li, Xiaoyan},
	urldate = {2023-10-25},
	date = {2023-07},
	langid = {english},
}

@incollection{lu_deep_2017,
	location = {Cham},
	title = {Deep Learning for Histopathological Image Analysis: Towards Computerized Diagnosis on Cancers},
	isbn = {978-3-319-42998-4 978-3-319-42999-1},
	url = {http://link.springer.com/10.1007/978-3-319-42999-1_6},
	shorttitle = {Deep Learning for Histopathological Image Analysis},
	pages = {73--95},
	booktitle = {Deep Learning and Convolutional Neural Networks for Medical Image Computing},
	publisher = {Springer International Publishing},
	author = {Xu, Jun and Zhou, Chao and Lang, Bing and Liu, Qingshan},
	editor = {Lu, Le and Zheng, Yefeng and Carneiro, Gustavo and Yang, Lin},
	urldate = {2021-12-23},
	date = {2017},
	doi = {10.1007/978-3-319-42999-1_6},
	note = {Series Title: Advances in Computer Vision and Pattern Recognition},
}

@article{litjens_survey_2017,
	title = {A survey on deep learning in medical image analysis},
	volume = {42},
	issn = {13618415},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841517301135},
	doi = {10.1016/j.media.2017.07.005},
	pages = {60--88},
	journaltitle = {Medical Image Analysis},
	shortjournal = {Medical Image Analysis},
	author = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen A.W.M. and van Ginneken, Bram and Sánchez, Clara I.},
	urldate = {2022-02-17},
	date = {2017-12},
	langid = {english},
	file = {Versión enviada:/home/maxi/Zotero/storage/88UK6C95/Litjens et al. - 2017 - A survey on deep learning in medical image analysi.pdf:application/pdf},
}

@book{weiler_maurice_and_forre_patrick_and_verlinde_erik_and_welling_max_equivariant_nodate,
	title = {Equivariant and Coordinate Independent Convolutional Networks},
	author = {Weiler, Maurice \{and\} Forré, Patrick \{and\} Verlinde, Erik \{and\} Welling, Max},
}

@online{noauthor_231101500_nodate,
	title = {[2311.01500] E(2) Equivariant Neural Networks for Robust Galaxy Morphology Classification},
	url = {https://arxiv.org/abs/2311.01500},
	urldate = {2023-12-09},
	file = {[2311.01500] E(2) Equivariant Neural Networks for Robust Galaxy Morphology Classification:/home/maxi/Zotero/storage/HH55U96E/2311.html:text/html},
}

@online{noauthor_patch_camelyon_nodate,
	title = {patch\_camelyon {\textbar} {TensorFlow} Datasets},
	url = {https://www.tensorflow.org/datasets/catalog/patch_camelyon},
	titleaddon = {{TensorFlow}},
	urldate = {2023-12-09},
	langid = {english},
	file = {Snapshot:/home/maxi/Zotero/storage/NQBYAB9S/patch_camelyon.html:text/html},
}

@article{song_artificial_2023,
	title = {Artificial intelligence for digital and computational pathology},
	volume = {1},
	rights = {2023  Springer Nature Limited},
	issn = {2731-6092},
	url = {https://www.nature.com/articles/s44222-023-00096-8},
	doi = {10.1038/s44222-023-00096-8},
	abstract = {Advances in digitizing tissue slides and the fast-paced progress in artificial intelligence, including deep learning, have boosted the field of computational pathology. This field holds tremendous potential to automate clinical diagnosis, predict patient prognosis and response to therapy, and discover new morphological biomarkers from tissue images. Some of these artificial intelligence-based systems are now getting approved to assist clinical diagnosis; however, technical barriers remain for their widespread clinical adoption and integration as a research tool. This Review consolidates recent methodological advances in computational pathology for predicting clinical end points in whole-slide images and highlights how these developments enable the automation of clinical practice and the discovery of new biomarkers. We then provide future perspectives as the field expands into a broader range of clinical and research tasks with increasingly diverse modalities of clinical data. Advances in digitizing human tissue slides and progress in artificial intelligence have boosted progress in the field of computational pathology. This Review consolidates recent methodological advances and provides future perspectives as the field expands to take on a broader range of clinical and research tasks.},
	pages = {930--949},
	number = {12},
	journaltitle = {Nature Reviews Bioengineering},
	shortjournal = {Nat Rev Bioeng},
	author = {Song, Andrew H. and Jaume, Guillaume and Williamson, Drew F. K. and Lu, Ming Y. and Vaidya, Anurag and Miller, Tiffany R. and Mahmood, Faisal},
	urldate = {2023-12-10},
	date = {2023-12},
	langid = {english},
	note = {Number: 12
Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, Computational science, Medical imaging, Pathology},
}

@online{noauthor_scripties_nodate,
	title = {Scripties - Bibliotheek - Universiteit van Amsterdam},
	url = {https://scripties.uba.uva.nl/},
	abstract = {Scripties van studenten van de Universiteit van Amsterdam.},
	urldate = {2023-12-13},
	langid = {dutch},
}

@article{sung_global_2021,
	title = {Global Cancer Statistics 2020: {GLOBOCAN} Estimates of Incidence and Mortality Worldwide for 36 Cancers in 185 Countries},
	volume = {71},
	issn = {0007-9235, 1542-4863},
	url = {https://acsjournals.onlinelibrary.wiley.com/doi/10.3322/caac.21660},
	doi = {10.3322/caac.21660},
	shorttitle = {Global Cancer Statistics 2020},
	abstract = {Abstract 
            This article provides an update on the global cancer burden using the {GLOBOCAN} 2020 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer. Worldwide, an estimated 19.3 million new cancer cases (18.1 million excluding nonmelanoma skin cancer) and almost 10.0 million cancer deaths (9.9 million excluding nonmelanoma skin cancer) occurred in 2020. Female breast cancer has surpassed lung cancer as the most commonly diagnosed cancer, with an estimated 2.3 million new cases (11.7\%), followed by lung (11.4\%), colorectal (10.0 \%), prostate (7.3\%), and stomach (5.6\%) cancers. Lung cancer remained the leading cause of cancer death, with an estimated 1.8 million deaths (18\%), followed by colorectal (9.4\%), liver (8.3\%), stomach (7.7\%), and female breast (6.9\%) cancers. Overall incidence was from 2‐fold to 3‐fold higher in transitioned versus transitioning countries for both sexes, whereas mortality varied {\textless}2‐fold for men and little for women. Death rates for female breast and cervical cancers, however, were considerably higher in transitioning versus transitioned countries (15.0 vs 12.8 per 100,000 and 12.4 vs 5.2 per 100,000, respectively). The global cancer burden is expected to be 28.4 million cases in 2040, a 47\% rise from 2020, with a larger increase in transitioning (64\% to 95\%) versus transitioned (32\% to 56\%) countries due to demographic changes, although this may be further exacerbated by increasing risk factors associated with globalization and a growing economy. Efforts to build a sustainable infrastructure for the dissemination of cancer prevention measures and provision of cancer care in transitioning countries is critical for global cancer control.},
	pages = {209--249},
	number = {3},
	journaltitle = {{CA}: A Cancer Journal for Clinicians},
	shortjournal = {{CA} A Cancer J Clinicians},
	author = {Sung, Hyuna and Ferlay, Jacques and Siegel, Rebecca L. and Laversanne, Mathieu and Soerjomataram, Isabelle and Jemal, Ahmedin and Bray, Freddie},
	urldate = {2023-12-13},
	date = {2021-05},
	langid = {english},
}

@article{priego-torresa_deep_2022,
	title = {Deep learning-based instance segmentation for the precise automated quantification of digital breast cancer immunohistochemistry images},
	volume = {193},
	issn = {09574174},
	url = {http://arxiv.org/abs/2311.13719},
	doi = {10.1016/j.eswa.2021.116471},
	abstract = {The quantification of biomarkers on immunohistochemistry breast cancer images is essential for defining appropriate therapy for breast cancer patients, as well as for extracting relevant information on disease prognosis. This is an arduous and time-consuming task that may introduce a bias in the results due to intra- and inter-observer variability which could be alleviated by making use of automatic quantification tools. However, this is not a simple processing task given the heterogeneity of breast tumors that results in non-uniformly distributed tumor cells exhibiting different staining colors and intensity, size, shape, and texture, of the nucleus, cytoplasm and membrane. In this research work, we demonstrate the feasibility of using a deep learning-based instance segmentation architecture for the automatic quantification of both nuclear and membrane biomarkers applied to {IHC}-stained slides. We have solved the cumbersome task of training set generation with the design and implementation of a web platform, which has served as a hub for communication and feedback between researchers and pathologists as well as a system for the validation of the automatic image processing models. Through this tool, we have collected annotations over samples of {HE}, {ER} and Ki-67 (nuclear biomarkers) and {HER}2 (membrane biomarker) {IHC}-stained images. Using the same deep learning network architecture, we have trained two models, so-called nuclei- and membrane-aware segmentation models, which, once successfully validated, have revealed to be a promising method to segment nuclei instances in {IHC}-stained images. The quantification method proposed in this work has been integrated into the developed web platform and is currently being used as a decision-support tool by pathologists.},
	pages = {116471},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Priego-Torresa, Blanca Maria and Lobato-Delgado, Barbara and Atienza-Cuevas, Lidia and Sanchez-Morillo, Daniel},
	urldate = {2024-01-25},
	date = {2022-05},
	eprinttype = {arxiv},
	eprint = {2311.13719 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Artificial Intelligence, I.4, J.6},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/WKRTG8DF/Priego-Torresa et al. - 2022 - Deep learning-based instance segmentation for the .pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/ICP6PY9V/2311.html:text/html},
}

@article{qiao_scale-rotation-equivariant_nodate,
	title = {Scale-Rotation-Equivariant Lie Group Convolution Neural Networks (Lie Group- {CNNs})},
	abstract = {The weight-sharing mechanism of convolutional kernels ensures translation-equivariance of convolution neural networks ({CNNs}). Recently, rotation-equivariance has been investigated. However, research on scale-equivariance or simultaneous scale-rotation-equivariance is insufficient. This study proposes a Lie group-{CNN}, which can keep scale-rotationequivariance for image classification tasks. The Lie group-{CNN} includes a lifting module, a series of group convolution modules, a global pooling layer, and a classification layer. The lifting module transfers the input image from Euclidean space n to Lie group space, and the group convolution is parameterized through a fully connected network using Lie-algebra of Lie-group elements as inputs to achieve scale-rotation-equivariance. The Lie group {SIM}(2) is utilized to establish the Lie group-{CNN} with scale-rotation-equivariance. Scale-rotation-equivariance of Lie group-{CNN} is verified and achieves the best recognition accuracy on the blood cell dataset (97.50\%) and the {HAM}10000 dataset (77.90\%) superior to Lie algebra convolution network, dilation convolution, spatial transformer network, and scale-equivariant steerable network. In addition, the generalization ability of the Lie group-{CNN} on {SIM}(2) on rotation-equivariance is verified on rotated-{MNIST} and rotated-{CIFAR}10, and the robustness of the network is verified on {SO}(2) and {SE}(2). Therefore, the Lie group-{CNN} can successfully extract geometric features and performs equivariant recognition on images with rotation and scale transformations.},
	author = {Qiao, Wei-Dong and Xu, Yang and Li, Hui},
	langid = {english},
	file = {Qiao et al. - Scale-Rotation-Equivariant Lie Group Convolution N.pdf:/home/maxi/Zotero/storage/G34V9AUX/Qiao et al. - Scale-Rotation-Equivariant Lie Group Convolution N.pdf:application/pdf},
}

@online{noauthor_httpswwwcisupennedujeaninterp-simpdf_nodate,
	title = {https://www.cis.upenn.edu/{\textasciitilde}jean/interp-{SIM}.pdf},
	url = {https://www.cis.upenn.edu/~jean/interp-SIM.pdf},
	urldate = {2024-04-10},
}

@article{allen_motion_nodate,
	title = {Motion Interpolation in {SIM}(3)},
	abstract = {In this paper, we explore motion interpolation in the group {SIM}(3), the group of aﬃne transformations which are the composition of a rotation, a translation, and a uniform rescaling. The group {SIM}(n) is a Lie group with Lie algebra sim(n), and we give a formula for the exponential map exp : sim(n) → {SIM}(n). We prove the surjectivity of the exponential map for any n ≥ 1, and for n = 3, we give an explicit formula and show how to compute logarithms. We use these algorithms for computing logarithms and exponentials to perform motion interpolation in {SIM}(3). Given a sequence A0, A1, . . . , An of transformations in {SIM}(3), we compute a sequence of logs X0, X1, . . . , Xn in sim(3) ≈ R7, then ﬁt a cubic spline c(t) that interpolates the Xi, and then compute the curve ec(t) in {SIM}(3). However, the fact that the logarithm is multivalued causes problems. Whenever a rotation “crosses through π,” the principal logarithm (the one associated with an angle in [0, π]) is not the correct choice and the motion goes “the long way.” To correct this problem, we choose the next log so that the length of the interpolating arc from Ai to Ai+1 is minimized. Unfortunately, we now obtain sequences of cubic splines with discontinuous junctions. To repair this problem, we introduce a class of sequences of cubic splines with discontinuous junctions but with continuity of the ﬁrst and second derivatives at junction points. Since the exponential map removes the discontinuities (because for two distinct logs X and Y of A ∈ {SIM}(3), we have {eX} = {eY} ), we obtain C2-continuous motions in {SIM}(3). We give several examples illustrating our implementation of the above methods.},
	author = {Allen, Christine and Leonardos, Spyridon and Gallier, Jean},
	langid = {english},
	file = {Allen et al. - Motion Interpolation in SIM(3).pdf:/home/maxi/Zotero/storage/TS3D8UX6/Allen et al. - Motion Interpolation in SIM(3).pdf:application/pdf},
}

@inproceedings{eilers_building_2023,
	title = {Building Blocks for a Complex-Valued Transformer Architecture},
	url = {http://arxiv.org/abs/2306.09827},
	doi = {10.1109/ICASSP49357.2023.10095349},
	abstract = {Most deep learning pipelines are built on real-valued operations to deal with real-valued inputs such as images, speech or music signals. However, a lot of applications naturally make use of complex-valued signals or images, such as {MRI} or remote sensing. Additionally the Fourier transform of signals is complex-valued and has numerous applications. We aim to make deep learning directly applicable to these complex-valued signals without using projections into \${\textbackslash}mathbb\{R\}{\textasciicircum}2\$. Thus we add to the recent developments of complex-valued neural networks by presenting building blocks to transfer the transformer architecture to the complex domain. We present multiple versions of a complex-valued Scaled Dot-Product Attention mechanism as well as a complex-valued layer normalization. We test on a classification and a sequence generation task on the {MusicNet} dataset and show improved robustness to overfitting while maintaining on-par performance when compared to the real-valued transformer architecture.},
	pages = {1--5},
	booktitle = {{ICASSP} 2023 - 2023 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	author = {Eilers, Florian and Jiang, Xiaoyi},
	urldate = {2024-04-24},
	date = {2023-06-04},
	eprinttype = {arxiv},
	eprint = {2306.09827 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/K4V5HSL2/Eilers and Jiang - 2023 - Building Blocks for a Complex-Valued Transformer A.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/J8JNZ63Z/2306.html:text/html},
}

@article{hirose_generalization_2012,
	title = {Generalization Characteristics of Complex-Valued Feedforward Neural Networks in Relation to Signal Coherence},
	volume = {23},
	issn = {2162-2388},
	url = {https://ieeexplore.ieee.org/document/6138313},
	doi = {10.1109/TNNLS.2012.2183613},
	abstract = {Applications of complex-valued neural networks ({CVNNs}) have expanded widely in recent years-in particular in radar and coherent imaging systems. In general, the most important merit of neural networks lies in their generalization ability. This paper compares the generalization characteristics of complex-valued and real-valued feedforward neural networks in terms of the coherence of the signals to be dealt with. We assume a task of function approximation such as interpolation of temporal signals. Simulation and real-world experiments demonstrate that {CVNNs} with amplitude-phase-type activation function show smaller generalization error than real-valued networks, such as bivariate and dual-univariate real-valued neural networks. Based on the results, we discuss how the generalization characteristics are influenced by the coherence of the signals depending on the degree of freedom in the learning and on the circularity in neural dynamics.},
	pages = {541--551},
	number = {4},
	journaltitle = {{IEEE} Transactions on Neural Networks and Learning Systems},
	author = {Hirose, Akira and Yoshida, Shotaro},
	urldate = {2024-04-24},
	date = {2012-04},
	note = {Conference Name: {IEEE} Transactions on Neural Networks and Learning Systems},
	keywords = {Biological neural networks, Coherence, Complex-valued neural network, Feedforward neural networks, function approximation, generalization, Neurons, Signal to noise ratio, supervised learning, Vectors},
	file = {IEEE Xplore Abstract Record:/home/maxi/Zotero/storage/Q7YYFC2Q/6138313.html:text/html},
}

@inproceedings{fletcher_gaussian_2003,
	location = {Berlin, Heidelberg},
	title = {Gaussian Distributions on Lie Groups and Their Application to Statistical Shape Analysis},
	isbn = {978-3-540-45087-0},
	doi = {10.1007/978-3-540-45087-0_38},
	abstract = {The Gaussian distribution is the basis for many methods used in the statistical analysis of shape. One such method is principal component analysis, which has proven to be a powerful technique for describing the geometric variability of a population of objects. The Gaussian framework is well understood when the data being studied are elements of a Euclidean vector space. This is the case for geometric objects that are described by landmarks or dense collections of boundary points. We have been using medial representations, or m-reps, for modelling the geometry of anatomical objects. The medial parameters are not elements of a Euclidean space, and thus standard {PCA} is not applicable. In our previous work we have shown that the m-rep model parameters are instead elements of a Lie group. In this paper we develop the notion of a Gaussian distribution on this Lie group. We then derive the maximum likelihood estimates of the mean and the covariance of this distribution. Analogous to principal component analysis of covariance in Euclidean spaces, we define principal geodesic analysis on Lie groups for the study of anatomical variability in medially-defined objects. Results of applying this framework on a population of hippocampi in a schizophrenia study are presented.},
	pages = {450--462},
	booktitle = {Information Processing in Medical Imaging},
	publisher = {Springer},
	author = {Fletcher, P. Thomas and Joshi, Sarang and Lu, Conglin and Pizer, Stephen M.},
	editor = {Taylor, Chris and Noble, J. Alison},
	date = {2003},
	langid = {english},
}

@inproceedings{nakashika_complex-valued_2020,
	title = {Complex-Valued Variational Autoencoder: A Novel Deep Generative Model for Direct Representation of Complex Spectra},
	url = {https://www.isca-archive.org/interspeech_2020/nakashika20_interspeech.html},
	doi = {10.21437/Interspeech.2020-1964},
	shorttitle = {Complex-Valued Variational Autoencoder},
	abstract = {In recent years, variational autoencoders ({VAEs}) have been attracting interest for many applications and generative tasks. Although the {VAE} is one of the most powerful deep generative models, it still has difﬁculty representing complex-valued data such as the complex spectra of speech. In speech synthesis, we usually use the {VAE} to encode Mel-cepstra, or raw amplitude spectra, from a speech signal into normally distributed latent features and then synthesize the speech from the reconstruction by using the Grifﬁn-Lim algorithm or other vocoders. Such inputs are originally calculated from complex spectra but lack the phase information, which leads to degradation when recovering speech. In this work, we propose a novel generative model to directly encode the complex spectra by extending the conventional {VAE}. The proposed model, which we call the complexvalued {VAE} ({CVAE}), consists of two complex-valued neural networks ({CVNNs}) of an encoder and a decoder. In the {CVAE}, not only the inputs and the parameters of the encoder and decoder but also the latent features are deﬁned as complex-valued to preserve the phase information throughout the network. The results of our speech encoding experiments demonstrated the effectiveness of the {CVAE} compared to the conventional {VAE} in both objective and subjective criteria.},
	eventtitle = {Interspeech 2020},
	pages = {2002--2006},
	booktitle = {Interspeech 2020},
	publisher = {{ISCA}},
	author = {Nakashika, Toru},
	urldate = {2024-05-04},
	date = {2020-10-25},
	langid = {english},
	file = {Nakashika - 2020 - Complex-Valued Variational Autoencoder A Novel De.pdf:/home/maxi/Zotero/storage/S3KZP7DT/Nakashika - 2020 - Complex-Valued Variational Autoencoder A Novel De.pdf:application/pdf},
}

@online{noauthor_httpswwwisca-archiveorginterspeech_2020nakashika20_interspeechpdf_nodate,
	title = {https://www.isca-archive.org/interspeech\_2020/nakashika20\_interspeech.pdf},
	url = {https://www.isca-archive.org/interspeech_2020/nakashika20_interspeech.pdf},
	urldate = {2024-05-04},
}

@incollection{duits_recent_2023,
	location = {Cham},
	title = {Recent Geometric Flows in Multi-orientation Image Processing via a Cartan Connection},
	isbn = {978-3-030-98661-2},
	url = {https://doi.org/10.1007/978-3-030-98661-2_101},
	abstract = {Applications of geometric flows to multi-orientation image processing require the choice of an (affine) connection on the Lie group G of roto-translations. Typical choices of such connections are called the (−), (0) and (+) connection. As the construction of these connections in standard references is quite involved, we provide an overview. We show that these connections are members of a larger, one-parameter class of connections, and we motivate that the (+) connection is most suited for our image analysis applications. The class ∇[ν], with ν∈ℝ\{{\textbackslash}textbackslashnu {\textbackslash}textbackslashin {\textbackslash}textbackslashmathbb \{R\}{\textbackslash}, is given by ∇X[ν]Y=ν[X,Y]\{{\textbackslash}textbackslashnabla \_\{X\}ˆ\{[{\textbackslash}textbackslashnu ]\}Y={\textbackslash}textbackslashnu {\textbackslash}textbackslash, [X,Y]{\textbackslash}for all left-invariant vector fields X, Y on G. Their auto-parallel curves are the exponential curves. Their torsion is T[X, Y ] = (2ν − 1)[X, Y ], and the (−), (0) and (+) connections arise for ν=0,12,1\{{\textbackslash}textbackslashnu =0, \{ {\textbackslash}textbackslashfrac \{1\}\{2\}\}, 1{\textbackslash}.},
	pages = {1525--1583},
	booktitle = {Handbook of Mathematical Models and Algorithms in Computer Vision and Imaging: Mathematical Imaging and Vision},
	publisher = {Springer International Publishing},
	author = {Duits, R. and Smets, B. M. N. and Wemmenhove, A. J. and Portegies, J. W. and Bekkers, E. J.},
	editor = {Chen, Ke and Schönlieb, Carola-Bibiane and Tai, Xue-Cheng and Younes, Laurent},
	urldate = {2023-10-08},
	date = {2023},
	langid = {english},
	doi = {10.1007/978-3-030-98661-2_101},
	keywords = {Cartan connections, Geodesic tracking, Geometric control, Medical image processing, Multi-orientation image processing, Riemannian geometry, sub-Riemannian geometry},
	file = {Duits et al. - Recent Geometric Flows in Multi-Orientation Image .pdf:/home/maxi/Zotero/storage/TZWFN9YL/Duits et al. - Recent Geometric Flows in Multi-Orientation Image .pdf:application/pdf},
}

@misc{weiler_coordinate_2021,
	title = {Coordinate Independent Convolutional Networks – Isometry and Gauge Equivariant Convolutions on Riemannian Manifolds},
	url = {http://arxiv.org/abs/2106.06020},
	abstract = {Motivated by the vast success of deep convolutional networks, there is a great interest in generalizing convolutions to non-Euclidean manifolds. A major complication in comparison to flat spaces is that it is unclear in which alignment a convolution kernel should be applied on a manifold. The underlying reason for this ambiguity is that general manifolds do not come with a canonical choice of reference frames (gauge). Kernels and features therefore have to be expressed relative to arbitrary coordinates. We argue that the particular choice of coordinatization should not affect a network's inference – it should be coordinate independent. A simultaneous demand for coordinate independence and weight sharing is shown to result in a requirement on the network to be equivariant under local gauge transformations (changes of local reference frames). The ambiguity of reference frames depends thereby on the G-structure of the manifold, such that the necessary level of gauge equivariance is prescribed by the corresponding structure group G. Coordinate independent convolutions are proven to be equivariant w.r.t. those isometries that are symmetries of the G-structure. The resulting theory is formulated in a coordinate free fashion in terms of fiber bundles. To exemplify the design of coordinate independent convolutions, we implement a convolutional network on the M{\textbackslash}textbackslash"obius strip. The generality of our differential geometric formulation of convolutional networks is demonstrated by an extensive literature review which explains a large number of Euclidean {CNNs}, spherical {CNNs} and {CNNs} on general surfaces as specific instances of coordinate independent convolutions.},
	publisher = {{arXiv}},
	author = {Weiler, Maurice and Forré, Patrick and Verlinde, Erik and Welling, Max},
	urldate = {2023-10-08},
	date = {2021-06},
	doi = {10.48550/arXiv.2106.06020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computational Geometry},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/MHTJ9MTF/Weiler et al. - 2021 - Coordinate Independent Convolutional Networks -- I.pdf:application/pdf},
}

@misc{esteves_theoretical_2020,
	title = {Theoretical Aspects of Group Equivariant Neural Networks},
	url = {http://arxiv.org/abs/2004.05154},
	abstract = {Group equivariant neural networks have been explored in the past few years and are interesting from theoretical and practical standpoints. They leverage concepts from group representation theory, non-commutative harmonic analysis and differential geometry that do not often appear in machine learning. In practice, they have been shown to reduce sample and model complexity, notably in challenging tasks where input transformations such as arbitrary rotations are present. We begin this work with an exposition of group representation theory and the machinery necessary to define and evaluate integrals and convolutions on groups. Then, we show applications to recent {SO}(3) and {SE}(3) equivariant networks, namely the Spherical {CNNs}, Clebsch-Gordan Networks, and 3D Steerable {CNNs}. We proceed to discuss two recent theoretical results. The first, by Kondor and Trivedi ({ICML}'18), shows that a neural network is group equivariant if and only if it has a convolutional structure. The second, by Cohen et al. ({NeurIPS}'19), generalizes the first to a larger class of networks, with feature maps as fields on homogeneous spaces.},
	publisher = {{arXiv}},
	author = {Esteves, Carlos},
	urldate = {2023-10-08},
	date = {2020-04},
	doi = {10.48550/arXiv.2004.05154},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/IFZTZATS/Esteves - 2020 - Theoretical Aspects of Group Equivariant Neural Ne.pdf:application/pdf},
}

@misc{bekkers_roto-translation_2018,
	title = {Roto-Translation Covariant Convolutional Networks for Medical Image Analysis},
	url = {http://arxiv.org/abs/1804.03393},
	abstract = {We propose a framework for rotation and translation covariant deep learning using {\textbackslash}{SE}(2){\textbackslash} group convolutions. The group product of the special Euclidean motion group {\textbackslash}{SE}(2){\textbackslash} describes how a concatenation of two roto-translations results in a net roto-translation. We encode this geometric structure into convolutional neural networks ({CNNs}) via {\textbackslash}{SE}(2){\textbackslash} group convolutional layers, which fit into the standard 2D {CNN} framework, and which allow to generically deal with rotated input samples without the need for data augmentation. We introduce three layers: a lifting layer which lifts a 2D (vector valued) image to an {\textbackslash}{SE}(2){\textbackslash}-image, i.e., 3D (vector valued) data whose domain is {\textbackslash}{SE}(2){\textbackslash}; a group convolution layer from and to an {\textbackslash}{SE}(2){\textbackslash}-image; and a projection layer from an {\textbackslash}{SE}(2){\textbackslash}-image to a 2D image. The lifting and group convolution layers are {\textbackslash}{SE}(2){\textbackslash} covariant (the output roto-translates with the input). The final projection layer, a maximum intensity projection over rotations, makes the full {CNN} rotation invariant. We show with three different problems in histopathology, retinal imaging, and electron microscopy that with the proposed group {CNNs}, state-of-the-art performance can be achieved, without the need for data augmentation by rotation and with increased performance compared to standard {CNNs} that do rely on augmentation.},
	publisher = {{arXiv}},
	author = {Bekkers, Erik J. and Lafarge, Maxime W. and Veta, Mitko and Eppenhof, Koen {AJ} and Pluim, Josien {PW} and Duits, Remco},
	urldate = {2023-10-08},
	date = {2018-06},
	doi = {10.48550/arXiv.1804.03393},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Mathematics - Group Theory, {toRead}, paper\_clave},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/FBH9RG6A/Bekkers et al. - 2018 - Roto-Translation Covariant Convolutional Networks .pdf:application/pdf},
}

@inproceedings{cesa_program_2021,
	title = {A Program to Build E(N)-Equivariant Steerable {CNNs}},
	url = {https://openreview.net/forum?id=WE4qe9xlnQw},
	abstract = {Equivariance is becoming an increasingly popular design choice to build data efficient neural networks by exploiting prior knowledge about the symmetries of the problem at hand. Euclidean steerable {CNNs} are one of the most common classes of equivariant networks. While the constraints these architectures need to satisfy are understood, existing approaches are tailored to specific (classes of) groups. No generally applicable method that is practical for implementation has been described so far. In this work, we generalize the Wigner-Eckart theorem proposed in Lang \& Weiler (2020), which characterizes general {\textbackslash}G{\textbackslash}-steerable kernel spaces for compact groups {\textbackslash}G{\textbackslash} over their homogeneous spaces, to arbitrary {\textbackslash}G{\textbackslash}-spaces. This enables us to directly parameterize filters in terms of a band-limited basis on the whole space rather than on {\textbackslash}G{\textbackslash}'s orbits, but also to easily implement steerable {CNNs} equivariant to a large number of groups. To demonstrate its generality, we instantiate our method on a variety of isometry groups acting on the Euclidean space \{{\textbackslash}textbackslashmathbb\{R\}ˆ3{\textbackslash}. Our framework allows us to build {\textbackslash}E(3){\textbackslash} and {\textbackslash}{SE}(3){\textbackslash}-steerable {CNNs} like previous works, but also {CNNs} with arbitrary {\textbackslash}G{\textbackslash}textbackslashleq O(3){\textbackslash}-steerable kernels. For example, we build 3D {CNNs} equivariant to the symmetries of platonic solids or choose {\textbackslash}G={SO}(2){\textbackslash} when working with 3D data having only azimuthal symmetries. We compare these models on 3D shapes and molecular datasets, observing improved performance by matching the model's symmetries to the ones of the data.},
	author = {Cesa, Gabriele and Lang, Leon and Weiler, Maurice},
	urldate = {2023-10-08},
	date = {2021-10},
	langid = {english},
	keywords = {paper\_clave},
	file = {Full Text PDF:/home/maxi/Zotero/storage/G3RE7U9V/Cesa et al. - 2021 - A Program to Build E(N)-Equivariant Steerable CNNs.pdf:application/pdf},
}

@misc{elesedy_provably_2021,
	title = {Provably Strict Generalisation Benefit for Equivariant Models},
	url = {http://arxiv.org/abs/2102.10333},
	abstract = {It is widely believed that engineering a model to be invariant/equivariant improves generalisation. Despite the growing popularity of this approach, a precise characterisation of the generalisation benefit is lacking. By considering the simplest case of linear models, this paper provides the first provably non-zero improvement in generalisation for invariant/equivariant models when the target distribution is invariant/equivariant with respect to a compact group. Moreover, our work reveals an interesting relationship between generalisation, the number of training examples and properties of the group action. Our results rest on an observation of the structure of function spaces under averaging operators which, along with its consequences for feature averaging, may be of independent interest.},
	publisher = {{arXiv}},
	author = {Elesedy, Bryn and Zaidi, Sheheryar},
	urldate = {2023-10-08},
	date = {2021-07},
	doi = {10.48550/arXiv.2102.10333},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/UB3J59SJ/Elesedy and Zaidi - 2021 - Provably Strict Generalisation Benefit for Equivar.pdf:application/pdf},
}

@misc{lang_wigner-eckart_2021,
	title = {A Wigner-Eckart Theorem for Group Equivariant Convolution Kernels},
	url = {http://arxiv.org/abs/2010.10952},
	abstract = {Group equivariant convolutional networks ({GCNNs}) endow classical convolutional networks with additional symmetry priors, which can lead to a considerably improved performance. Recent advances in the theoretical description of {GCNNs} revealed that such models can generally be understood as performing convolutions with G-steerable kernels, that is, kernels that satisfy an equivariance constraint themselves. While the G-steerability constraint has been derived, it has to date only been solved for specific use cases - a general characterization of G-steerable kernel spaces is still missing. This work provides such a characterization for the practically relevant case of G being any compact group. Our investigation is motivated by a striking analogy between the constraints underlying steerable kernels on the one hand and spherical tensor operators from quantum mechanics on the other hand. By generalizing the famous Wigner-Eckart theorem for spherical tensor operators, we prove that steerable kernel spaces are fully understood and parameterized in terms of 1) generalized reduced matrix elements, 2) Clebsch-Gordan coefficients, and 3) harmonic basis functions on homogeneous spaces.},
	publisher = {{arXiv}},
	author = {Lang, Leon and Weiler, Maurice},
	urldate = {2023-10-08},
	date = {2021-01},
	doi = {10.48550/arXiv.2010.10952},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/S6DFZ3NZ/Lang and Weiler - 2021 - A Wigner-Eckart Theorem for Group Equivariant Conv.pdf:application/pdf},
}

@misc{kondor_generalization_2018,
	title = {On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups},
	url = {http://arxiv.org/abs/1802.03690},
	abstract = {Convolutional neural networks have been extremely successful in the image recognition domain because they ensure equivariance to translations. There have been many recent attempts to generalize this framework to other domains, including graphs and data lying on manifolds. In this paper we give a rigorous, theoretical treatment of convolution and equivariance in neural networks with respect to not just translations, but the action of any compact group. Our main result is to prove that (given some natural constraints) convolutional structure is not just a sufficient, but also a necessary condition for equivariance to the action of a compact group. Our exposition makes use of concepts from representation theory and noncommutative harmonic analysis and derives new generalized convolution formulae.},
	publisher = {{arXiv}},
	author = {Kondor, Risi and Trivedi, Shubhendu},
	urldate = {2023-10-08},
	date = {2018-11},
	doi = {10.48550/arXiv.1802.03690},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/JENX32HT/Kondor and Trivedi - 2018 - On the Generalization of Equivariance and Convolut.pdf:application/pdf},
}

@misc{masci_geodesic_2018,
	title = {Geodesic convolutional neural networks on Riemannian manifolds},
	url = {http://arxiv.org/abs/1501.06297},
	abstract = {Feature descriptors play a crucial role in a wide range of geometry analysis and processing applications, including shape correspondence, retrieval, and segmentation. In this paper, we introduce Geodesic Convolutional Neural Networks ({GCNN}), a generalization of the convolutional networks ({CNN}) paradigm to non-Euclidean manifolds. Our construction is based on a local geodesic system of polar coordinates to extract "patches", which are then passed through a cascade of filters and linear and non-linear operators. The coefficients of the filters and linear combination weights are optimization variables that are learned to minimize a task-specific cost function. We use {GCNN} to learn invariant shape features, allowing to achieve state-of-the-art performance in problems such as shape description, retrieval, and correspondence.},
	publisher = {{arXiv}},
	author = {Masci, Jonathan and Boscaini, Davide and Bronstein, Michael M. and Vandergheynst, Pierre},
	urldate = {2023-10-08},
	date = {2018-06},
	doi = {10.48550/arXiv.1501.06297},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/XJXGGZXX/Masci et al. - 2018 - Geodesic convolutional neural networks on Riemanni.pdf:application/pdf},
}

@misc{cohen_group_2016,
	title = {Group Equivariant Convolutional Networks},
	url = {http://arxiv.org/abs/1602.07576},
	abstract = {We introduce Group equivariant Convolutional Neural Networks (G-{CNNs}), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-{CNNs} use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-{CNNs} achieve state of the art results on {CIFAR}10 and rotated {MNIST}.},
	publisher = {{arXiv}},
	author = {Cohen, Taco S. and Welling, Max},
	urldate = {2023-10-08},
	date = {2016-06},
	doi = {10.48550/arXiv.1602.07576},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/J2NJ2YEJ/Cohen and Welling - 2016 - Group Equivariant Convolutional Networks.pdf:application/pdf},
}

@misc{noauthor_161205877_nodate,
	title = {[1612.05877] Deep Learning on Lie Groups for Skeleton-based Action Recognition},
	url = {https://arxiv.org/abs/1612.05877},
	urldate = {2023-10-08},
}

@misc{noauthor_200109046_nodate,
	title = {[2001.09046] {PDE}-based Group Equivariant Convolutional Neural Networks},
	url = {https://arxiv.org/abs/2001.09046},
	urldate = {2023-10-08},
}

@misc{noauthor_230518415_nodate-1,
	title = {[2305.18415] Geometric Algebra Transformers},
	url = {https://arxiv.org/abs/2305.18415},
	urldate = {2023-10-08},
}

@misc{noauthor_210209844_nodate,
	title = {[2102.09844] E(n) Equivariant Graph Neural Networks},
	url = {https://arxiv.org/abs/2102.09844},
	urldate = {2023-10-08},
	keywords = {{toRead}},
}

@misc{noauthor_210608903_nodate,
	title = {[2106.08903] {GemNet}: Universal Directional Graph Neural Networks for Molecules},
	url = {https://arxiv.org/abs/2106.08903},
	urldate = {2023-10-08},
}

@misc{noauthor_200604780_nodate,
	title = {[2006.04780] Lorentz Group Equivariant Neural Network for Particle Physics},
	url = {https://arxiv.org/abs/2006.04780},
	urldate = {2023-10-08},
}

@misc{noauthor_180609231_nodate,
	title = {[1806.09231] Clebsch-Gordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network},
	url = {https://arxiv.org/abs/1806.09231},
	urldate = {2023-10-08},
}

@misc{noauthor_220709453_nodate-1,
	title = {[2207.09453] e3nn: Euclidean Neural Networks},
	url = {https://arxiv.org/abs/2207.09453},
	urldate = {2023-10-08},
}

@misc{noauthor_230504431_nodate-1,
	title = {[2305.04431] Lie Group Algebra Convolutional Filters},
	url = {https://arxiv.org/abs/2305.04431},
	urldate = {2023-10-08},
}

@misc{noauthor_180505533_nodate,
	title = {[1805.05533] Discovering Transforms: A Tutorial on Circulant Matrices, Circular Convolution, and the Discrete Fourier Transform},
	url = {https://arxiv.org/abs/1805.05533},
	urldate = {2023-10-08},
}

@misc{noauthor_180208219_nodate,
	title = {[1802.08219] Tensor field networks: Rotation- and translation-equivariant neural networks for 3D point clouds},
	url = {https://arxiv.org/abs/1802.08219},
	urldate = {2023-10-08},
}

@misc{noauthor_210907103v2_nodate,
	title = {[2109.07103v2] Automatic Symmetry Discovery with Lie Algebra Convolutional Network},
	url = {https://arxiv.org/abs/2109.07103v2},
	urldate = {2023-10-08},
}

@misc{noauthor_221112786_nodate-1,
	title = {[2211.12786] Nonlinear Equivariant Imaging: Learning Multi-Parametric Tissue Mapping without Ground Truth for Compressive Quantitative {MRI}},
	url = {https://arxiv.org/abs/2211.12786},
	urldate = {2023-10-09},
}

@misc{noauthor_211112139_nodate,
	title = {[2111.12139] {ChebLieNet}: Invariant Spectral Graph {NNs} Turned Equivariant by Riemannian Geometry on Lie Groups},
	url = {https://arxiv.org/abs/2111.12139},
	urldate = {2023-10-08},
}

@misc{noauthor_200305425_nodate,
	title = {[2003.05425] Gauge Equivariant Mesh {CNNs}: Anisotropic convolutions on geometric graphs},
	url = {https://arxiv.org/abs/2003.05425},
	urldate = {2023-10-08},
}

@misc{noauthor_201000977_nodate,
	title = {[2010.00977] Group Equivariant Stand-Alone Self-Attention For Vision},
	url = {https://arxiv.org/abs/2010.00977},
	urldate = {2023-10-08},
}

@misc{noauthor_210205013_nodate,
	title = {[2102.05013] Spherical Message Passing for 3D Graph Networks},
	url = {https://arxiv.org/abs/2102.05013},
	urldate = {2023-10-08},
}

@misc{noauthor_210203150_nodate,
	title = {[2102.03150] Equivariant message passing for the prediction of tensorial properties and molecular spectra},
	url = {https://arxiv.org/abs/2102.03150},
	urldate = {2023-10-08},
}

@misc{noauthor_200610503_nodate,
	title = {[2006.10503] {SE}(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks},
	url = {https://arxiv.org/abs/2006.10503},
	urldate = {2023-10-08},
}

@misc{noauthor_161204642_nodate,
	title = {[1612.04642] Harmonic Networks: Deep Translation and Rotation Equivariance},
	url = {https://arxiv.org/abs/1612.04642},
	urldate = {2023-10-08},
}

@misc{ferreira_are_2023,
	title = {Are foundation models efficient for medical image segmentation?},
	url = {http://arxiv.org/abs/2311.04847},
	abstract = {Foundation models are experiencing a surge in popularity. The Segment Anything model ({SAM}) asserts an ability to segment a wide spectrum of objects but required supervised training at unprecedented scale. We compared {SAM}'s performance (against clinical ground truth) and resources (labeling time, compute) to a modality-specific, label-free self-supervised learning ({SSL}) method on 25 measurements for 100 cardiac ultrasounds. {SAM} performed poorly and required significantly more labeling and computing resources, demonstrating worse efficiency than {SSL}.},
	publisher = {{arXiv}},
	author = {Ferreira, Danielle and Arnaout, Rima},
	urldate = {2023-12-06},
	date = {2023-11},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/LI2YS8P9/Ferreira y Arnaout - 2023 - Are foundation models efficient for medical image .pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/MT3D2J89/2311.html:text/html},
}

@misc{kirillov_segment_2023,
	title = {Segment Anything},
	url = {http://arxiv.org/abs/2304.02643},
	abstract = {We introduce the Segment Anything ({SA}) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive – often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model ({SAM}) and corresponding dataset ({SA}-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
	publisher = {{arXiv}},
	author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
	urldate = {2023-12-06},
	date = {2023-04},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/FS9DF3N8/Kirillov et al. - 2023 - Segment Anything.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/JQWMLTYT/2304.html:text/html},
}

@misc{bommasani_opportunities_2022,
	title = {On the Opportunities and Risks of Foundation Models},
	url = {http://arxiv.org/abs/2108.07258},
	abstract = {{AI} is undergoing a paradigm shift with the rise of models (e.g., {BERT}, {DALL}-E, {GPT}-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
	publisher = {{arXiv}},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	urldate = {2023-11-04},
	date = {2022-07},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/H7TX5M9J/Bommasani et al. - 2022 - On the Opportunities and Risks of Foundation Model.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/5CWK5CV7/2108.html:text/html},
}

@article{hu_state---art_2023-1,
	title = {A state-of-the-art survey of artificial neural networks for Whole-slide Image analysis: From popular Convolutional Neural Networks to potential visual transformers},
	volume = {161},
	issn = {00104825},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010482523004997},
	doi = {10.1016/j.compbiomed.2023.107034},
	shorttitle = {A state-of-the-art survey of artificial neural networks for Whole-slide Image analysis},
	pages = {107034},
	journaltitle = {Computers in Biology and Medicine},
	author = {Hu, Weiming and Li, Xintong and Li, Chen and Li, Rui and Jiang, Tao and Sun, Hongzan and Huang, Xinyu and Grzegorzek, Marcin and Li, Xiaoyan},
	urldate = {2023-10-25},
	date = {2023-07},
	langid = {english},
}

@misc{zhdanov_implicit_2023,
	title = {Implicit Convolutional Kernels for Steerable {CNNs}},
	url = {http://arxiv.org/abs/2212.06096},
	abstract = {Steerable convolutional neural networks ({CNNs}) provide a general framework for building neural networks equivariant to translations and other transformations belonging to an origin-preserving group {\textbackslash}G{\textbackslash}, such as reflections and rotations. They rely on standard convolutions with {\textbackslash}G{\textbackslash}-steerable kernels obtained by analytically solving the group-specific equivariance constraint imposed onto the kernel space. As the solution is tailored to a particular group {\textbackslash}G{\textbackslash}, the implementation of a kernel basis does not generalize to other symmetry transformations, which complicates the development of general group equivariant models. We propose using implicit neural representation via multi-layer perceptrons ({MLPs}) to parameterize {\textbackslash}G{\textbackslash}-steerable kernels. The resulting framework offers a simple and flexible way to implement Steerable {CNNs} and generalizes to any group {\textbackslash}G{\textbackslash} for which a {\textbackslash}G{\textbackslash}-equivariant {MLP} can be built. We prove the effectiveness of our method on multiple tasks, including N-body simulations, point cloud classification and molecular property prediction.},
	publisher = {{arXiv}},
	author = {Zhdanov, Maksim and Hoffmann, Nico and Cesa, Gabriele},
	urldate = {2023-10-25},
	date = {2023-10},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
}

@misc{romero_group_2021,
	title = {Group Equivariant Stand-Alone Self-Attention For Vision},
	url = {http://arxiv.org/abs/2010.00977},
	abstract = {We provide a general self-attention formulation to impose group equivariance to arbitrary symmetry groups. This is achieved by defining positional encodings that are invariant to the action of the group considered. Since the group acts on the positional encoding directly, group equivariant self-attention networks ({GSA}-Nets) are steerable by nature. Our experiments on vision benchmarks demonstrate consistent improvements of {GSA}-Nets over non-equivariant self-attention networks.},
	publisher = {{arXiv}},
	author = {Romero, David W. and Cordonnier, Jean-Baptiste},
	urldate = {2023-10-18},
	date = {2021-03},
	keywords = {Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/AWF27G4I/Romero y Cordonnier - 2021 - Group Equivariant Stand-Alone Self-Attention For V.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/VFG527FY/2010.html:text/html},
}

@misc{kipf_semi-supervised_2017,
	title = {Semi-Supervised Classification with Graph Convolutional Networks},
	url = {http://arxiv.org/abs/1609.02907},
	abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
	publisher = {{arXiv}},
	author = {Kipf, Thomas N. and Welling, Max},
	urldate = {2023-12-09},
	date = {2017-02},
	doi = {10.48550/arXiv.1609.02907},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/UG4U44S3/Kipf and Welling - 2017 - Semi-Supervised Classification with Graph Convolut.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/M8UCANET/1609.html:text/html},
}

@misc{hataya_noncommutative_2023,
	title = {Noncommutative \{Cˆ*{\textbackslash}-algebra Net: Learning Neural Networks with Powerful Product Structure in \{Cˆ*{\textbackslash}-algebra},
	url = {http://arxiv.org/abs/2302.01191},
	shorttitle = {Noncommutative \{Cˆ*{\textbackslash}-algebra Net},
	abstract = {We propose a new generalization of neural networks with noncommutative {\textbackslash}Cˆ*{\textbackslash}-algebra. An important feature of {\textbackslash}Cˆ*{\textbackslash}-algebras is their noncommutative structure of products, but the existing {\textbackslash}Cˆ*{\textbackslash}-algebra net frameworks have only considered commutative {\textbackslash}Cˆ*{\textbackslash}-algebras. We show that this noncommutative structure of {\textbackslash}Cˆ*{\textbackslash}-algebras induces powerful effects in learning neural networks. Our framework has a wide range of applications, such as learning multiple related neural networks simultaneously with interactions and learning invariant features with respect to group actions. We also show the validity of our framework numerically, which illustrates its potential power.},
	publisher = {{arXiv}},
	author = {Hataya, Ryuichiro and Hashimoto, Yuka},
	urldate = {2023-12-09},
	date = {2023-01},
	doi = {10.48550/arXiv.2302.01191},
	keywords = {Computer Science - Machine Learning, Mathematics - Functional Analysis, Mathematics - Operator Algebras},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/7VMJZLSE/Hataya and Hashimoto - 2023 - Noncommutative \$C^\$-algebra Net Learning Neural .pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/K8J56JXW/2302.html:text/html},
}

@misc{rocca_understanding_2021,
	title = {Understanding Variational Autoencoders ({VAEs})},
	url = {https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73},
	abstract = {Building, step by step, the reasoning that leads to {VAEs}.},
	author = {Rocca, Joseph},
	urldate = {2023-12-09},
	date = {2021-03},
	langid = {english},
	note = {Publication Title: Medium},
	file = {Snapshot:/home/maxi/Zotero/storage/FLWVCSUZ/understanding-variational-autoencoders-vaes-f70510919f73.html:text/html},
}

@misc{noauthor_231101500_nodate-1,
	title = {[2311.01500] E(2) Equivariant Neural Networks for Robust Galaxy Morphology Classification},
	url = {https://arxiv.org/abs/2311.01500},
	urldate = {2023-12-09},
	file = {[2311.01500] E(2) Equivariant Neural Networks for Robust Galaxy Morphology Classification:/home/maxi/Zotero/storage/XRCZEEIZ/2311.html:text/html},
}

@misc{nishikawa-toomey_semi-supervised_2020,
	title = {Semi-supervised Learning of Galaxy Morphology using Equivariant Transformer Variational Autoencoders},
	url = {http://arxiv.org/abs/2011.08714},
	abstract = {The growth in the number of galaxy images is much faster than the speed at which these galaxies can be labelled by humans. However, by leveraging the information present in the ever growing set of unlabelled images, semi-supervised learning could be an effective way of reducing the required labelling and increasing classification accuracy. We develop a Variational Autoencoder ({VAE}) with Equivariant Transformer layers with a classifier network from the latent space. We show that this novel architecture leads to improvements in accuracy when used for the galaxy morphology classification task on the Galaxy Zoo data set. In addition we show that pre-training the classifier network as part of the {VAE} using the unlabelled data leads to higher accuracy with fewer labels compared to exiting approaches. This novel {VAE} has the potential to automate galaxy morphology classification with reduced human labelling efforts.},
	publisher = {{arXiv}},
	author = {Nishikawa-Toomey, Mizu and Smith, Lewis and Gal, Yarin},
	urldate = {2023-12-09},
	date = {2020-11},
	doi = {10.48550/arXiv.2011.08714},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/TJT4WM3Z/Nishikawa-Toomey et al. - 2020 - Semi-supervised Learning of Galaxy Morphology usin.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/NUJMZZ6I/2011.html:text/html},
}

@misc{noauthor_patch_camelyon_nodate-1,
	title = {patch\_camelyon {\textbackslash}textbar {TensorFlow} Datasets},
	url = {https://www.tensorflow.org/datasets/catalog/patch_camelyon},
	urldate = {2023-12-09},
	langid = {english},
	note = {Publication Title: {TensorFlow}},
	file = {Snapshot:/home/maxi/Zotero/storage/V6NJ5XZL/patch_camelyon.html:text/html},
}

@article{verghese_computational_2023,
	title = {Computational pathology in cancer diagnosis, prognosis, and prediction – present day and prospects},
	volume = {260},
	issn = {0022-3417, 1096-9896},
	url = {https://pathsocjournals.onlinelibrary.wiley.com/doi/10.1002/path.6163},
	doi = {10.1002/path.6163},
	abstract = {Abstract Computational pathology refers to applying deep learning techniques and algorithms to analyse and interpret histopathology images. Advances in artificial intelligence ({AI}) have led to an explosion in innovation in computational pathology, ranging from the prospect of automation of routine diagnostic tasks to the discovery of new prognostic and predictive biomarkers from tissue morphology. Despite the promising potential of computational pathology, its integration in clinical settings has been limited by a range of obstacles including operational, technical, regulatory, ethical, financial, and cultural challenges. Here, we focus on the pathologists’ perspective of computational pathology: we map its current translational research landscape, evaluate its clinical utility, and address the more common challenges slowing clinical adoption and implementation. We conclude by describing contemporary approaches to drive forward these techniques. © 2023 The Authors. The Journal of Pathology published by John Wiley \& Sons Ltd on behalf of The Pathological Society of Great Britain and Ireland.},
	pages = {551--563},
	number = {5},
	journaltitle = {The Journal of Pathology},
	author = {Verghese, Gregory and Lennerz, Jochen K and Ruta, Danny and Ng, Wen and Thavaraj, Selvam and Siziopikou, Kalliopi P and Naidoo, Threnesan and Rane, Swapnil and Salgado, Roberto and Pinder, Sarah E and Grigoriadis, Anita},
	urldate = {2023-12-13},
	date = {2023-08},
	langid = {english},
}

@misc{mcgenity_navigating_2023,
	title = {Navigating the reporting guideline environment for computational pathology: A review},
	url = {http://arxiv.org/abs/2301.09985},
	shorttitle = {Navigating the reporting guideline environment for computational pathology},
	abstract = {The application of new artificial intelligence ({AI}) discoveries is transforming healthcare research. However, the standards of reporting are variable in this still evolving field, leading to potential research waste. The aim of this work is to highlight resources and reporting guidelines available to researchers working in computational pathology. The {EQUATOR} Network library of reporting guidelines and extensions was systematically searched up to August 2022 to identify applicable resources. Inclusion and exclusion criteria were used and guidance was screened for utility at different stages of research and for a range of study types. Items were compiled to create a summary for easy identification of useful resources and guidance. Over 70 published resources applicable to pathology {AI} research were identified. Guidelines were divided into key categories, reflecting current study types and target areas for {AI} research: Literature \& Research Priorities, Discovery, Clinical Trial, Implementation and Post-Implementation \& Guidelines. Guidelines useful at multiple stages of research and those currently in development were also highlighted. Summary tables with links to guidelines for these groups were developed, to assist those working in cancer {AI} research with complete reporting of research. Issues with replication and research waste are recognised problems in {AI} research. Reporting guidelines can be used as templates to ensure the essential information needed to replicate research is included within journal articles and abstracts. Reporting guidelines are available and useful for many study types, but greater awareness is needed to encourage researchers to utilise them and for journals to adopt them. This review and summary of resources highlights guidance to researchers, aiming to improve completeness of reporting.},
	publisher = {{arXiv}},
	author = {{McGenity}, Clare and Treanor, Darren},
	urldate = {2023-12-13},
	date = {2023-01},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, I.2.1},
}

@misc{noauthor_scripties_nodate-1,
	title = {Scripties - Bibliotheek - Universiteit van Amsterdam},
	url = {https://scripties.uba.uva.nl/},
	abstract = {Scripties van studenten van de Universiteit van Amsterdam.},
	urldate = {2023-12-13},
	langid = {dutch},
}

@misc{cohen_general_2020,
	title = {A General Theory of Equivariant {CNNs} on Homogeneous Spaces},
	url = {http://arxiv.org/abs/1811.02017},
	abstract = {We present a general theory of Group equivariant Convolutional Neural Networks (G-{CNNs}) on homogeneous spaces such as Euclidean space and the sphere. Feature maps in these networks represent fields on a homogeneous base space, and layers are equivariant maps between spaces of fields. The theory enables a systematic classification of all existing G-{CNNs} in terms of their symmetry group, base space, and field type. We also consider a fundamental question: what is the most general kind of equivariant linear map between feature spaces (fields) of given types? Following Mackey, we show that such maps correspond one-to-one with convolutions using equivariant kernels, and characterize the space of such kernels.},
	publisher = {{arXiv}},
	author = {Cohen, Taco and Geiger, Mario and Weiler, Maurice},
	urldate = {2023-12-13},
	date = {2020-01},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computational Geometry, Computer Science - Artificial Intelligence},
}

@misc{huang_ki-67_2022,
	title = {Ki-67 Index Measurement in Breast Cancer Using Digital Image Analysis},
	url = {http://arxiv.org/abs/2209.13155},
	abstract = {Ki-67 is a nuclear protein that can be produced during cell proliferation. The Ki67 index is a valuable prognostic variable in several kinds of cancer. In breast cancer, the index is even routinely checked in many patients. Currently, pathologists use the immunohistochemistry method to calculate the percentage of Ki-67 positive malignant cells as Ki-67 index. The higher score usually means more aggressive tumor behavior. In clinical practice, the measurement of Ki-67 index relies on visual identifying method and manual counting. However, visual and manual assessment method is timeconsuming and leads to poor reproducibility because of different scoring standards or limited tumor area under assessment. Here, we use digital image processing technics including image binarization and image morphological operations to create a digital image analysis method to interpretate Ki-67 index. Then, 10 breast cancer specimens are used as validation with high accuracy (correlation efficiency r = 0.95127). With the assistance of digital image analysis, pathologists can interpretate the Ki67 index more efficiently, precisely with excellent reproducibility.},
	publisher = {{arXiv}},
	author = {Huang, Hsiang-Wei and Huang, Wen-Tsung and Tsai, Hsun-Heng},
	urldate = {2024-01-25},
	date = {2022-09},
	doi = {10.48550/arXiv.2209.13155},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/LN58D9W7/Huang et al. - 2022 - Ki-67 Index Measurement in Breast Cancer Using Dig.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/8VZPGNSC/2209.html:text/html},
}

@article{benediktsson_pathology_2007,
	title = {Pathology Services in Developing Countries: A Challenge},
	volume = {131},
	issn = {0003-9985},
	url = {https://doi.org/10.5858/2007-131-1636-PSIDCA},
	doi = {10.5858/2007-131-1636-PSIDCA},
	shorttitle = {Pathology Services in Developing Countries},
	pages = {1636--1639},
	number = {11},
	journaltitle = {Archives of Pathology \& Laboratory Medicine},
	author = {Benediktsson, Hallgrímur and Whitelaw, John and Roy, Indrojit},
	urldate = {2024-01-31},
	date = {2007-11},
	file = {Full Text PDF:/home/maxi/Zotero/storage/GEAMG8K4/Benediktsson et al. - 2007 - Pathology Services in Developing Countries A Chal.pdf:application/pdf;Snapshot:/home/maxi/Zotero/storage/R4K559CK/Pathology-Services-in-Developing-Countries-A.html:text/html},
}

@article{tellez_neural_2021,
	title = {Neural Image Compression for Gigapixel Histopathology Image Analysis},
	volume = {43},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {http://arxiv.org/abs/1811.02840},
	doi = {10.1109/TPAMI.2019.2936841},
	abstract = {We propose Neural Image Compression ({NIC}), a two-step method to build convolutional neural networks for gigapixel image analysis solely using weak image-level labels. First, gigapixel images are compressed using a neural network trained in an unsupervised fashion, retaining high-level information while suppressing pixel-level noise. Second, a convolutional neural network ({CNN}) is trained on these compressed image representations to predict image-level labels, avoiding the need for fine-grained manual annotations. We compared several encoding strategies, namely reconstruction error minimization, contrastive training and adversarial feature learning, and evaluated {NIC} on a synthetic task and two public histopathology datasets. We found that {NIC} can exploit visual cues associated with image-level labels successfully, integrating both global and local visual information. Furthermore, we visualized the regions of the input gigapixel images where the {CNN} attended to, and confirmed that they overlapped with annotations from human experts.},
	pages = {567--578},
	number = {2},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Tellez, David and Litjens, Geert and van der Laak, Jeroen and Ciompi, Francesco},
	urldate = {2024-02-14},
	date = {2021-02},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/I7S2VSDU/Tellez et al. - 2021 - Neural Image Compression for Gigapixel Histopathol.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/48CG6EJB/1811.html:text/html},
}

@misc{gong_lie_2019,
	title = {Lie Group Auto-Encoder},
	url = {http://arxiv.org/abs/1901.09970},
	abstract = {In this paper, we propose an auto-encoder based generative neural network model whose encoder compresses the inputs into vectors in the tangent space of a special Lie group manifold: upper triangular positive definite affine transform matrices ({UTDATs}). {UTDATs} are representations of Gaussian distributions and can straightforwardly generate Gaussian distributed samples. Therefore, the encoder is trained together with a decoder (generator) which takes Gaussian distributed latent vectors as input. Compared with related generative models such as variational auto-encoder, the proposed model incorporates the information on geometric properties of Gaussian distributions. As a special case, we derive an exponential mapping layer for diagonal Gaussian {UTDATs} which eliminates matrix exponential operator compared with general exponential mapping in Lie group theory. Moreover, we derive an intrinsic loss for {UTDAT} Lie group which can be calculated as l-2 loss in the tangent space. Furthermore, inspired by the Lie group theory, we propose to use the Lie algebra vectors rather than the raw parameters (e.g. mean) of Gaussian distributions as compressed representations of original inputs. Experimental results verity the effectiveness of the proposed new generative model and the benefits gained from the Lie group structural information of {UTDATs}.},
	publisher = {{arXiv}},
	author = {Gong, Liyu and Cheng, Qiang},
	urldate = {2024-03-19},
	date = {2019-01},
	doi = {10.48550/arXiv.1901.09970},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Group Theory},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/VABGLVP7/Gong and Cheng - 2019 - Lie Group Auto-Encoder.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/C55ZTED4/1901.html:text/html},
}

@misc{khetan_implicit_2021,
	title = {Implicit Equivariance in Convolutional Networks},
	url = {http://arxiv.org/abs/2111.14157},
	abstract = {Convolutional Neural Networks({CNN}) are inherently equivariant under translations, however, they do not have an equivalent embedded mechanism to handle other transformations such as rotations and change in scale. Several approaches exist that make {CNNs} equivariant under other transformation groups by design. Among these, steerable {CNNs} have been especially effective. However, these approaches require redesigning standard networks with filters mapped from combinations of predefined basis involving complex analytical functions. We experimentally demonstrate that these restrictions in the choice of basis can lead to model weights that are sub-optimal for the primary deep learning task (e.g. classification). Moreover, such hard-baked explicit formulations make it difficult to design composite networks comprising heterogeneous feature groups. To circumvent such issues, we propose Implicitly Equivariant Networks ({IEN}) which induce equivariance in the different layers of a standard {CNN} model by optimizing a multi-objective loss function that combines the primary loss with an equivariance loss term. Through experiments with {VGG} and {ResNet} models on Rot-{MNIST} , Rot-{TinyImageNet}, Scale-{MNIST} and {STL}-10 datasets, we show that {IEN}, even with its simple formulation, performs better than steerable networks. Also, {IEN} facilitates construction of heterogeneous filter groups allowing reduction in number of channels in {CNNs} by a factor of over 30\% while maintaining performance on par with baselines. The efficacy of {IEN} is further validated on the hard problem of visual object tracking. We show that {IEN} outperforms the state-of-the-art rotation equivariant tracking method while providing faster inference speed.},
	publisher = {{arXiv}},
	author = {Khetan, Naman and Arora, Tushar and Rehman, Samee Ur and Gupta, Deepak K.},
	urldate = {2024-04-01},
	date = {2021-11},
	doi = {10.48550/arXiv.2111.14157},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/CBBQNIEM/Khetan et al. - 2021 - Implicit Equivariance in Convolutional Networks.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/MQEUWCWV/2111.html:text/html},
}

@misc{macdonald_enabling_2022,
	title = {Enabling equivariance for arbitrary Lie groups},
	url = {http://arxiv.org/abs/2111.08251},
	abstract = {Although provably robust to translational perturbations, convolutional neural networks ({CNNs}) are known to suffer from extreme performance degradation when presented at test time with more general geometric transformations of inputs. Recently, this limitation has motivated a shift in focus from {CNNs} to Capsule Networks ({CapsNets}). However, {CapsNets} suffer from admitting relatively few theoretical guarantees of invariance. We introduce a rigourous mathematical framework to permit invariance to any Lie group of warps, exclusively using convolutions (over Lie groups), without the need for capsules. Previous work on group convolutions has been hampered by strong assumptions about the group, which precludes the application of such techniques to common warps in computer vision such as affine and homographic. Our framework enables the implementation of group convolutions over any finite-dimensional Lie group. We empirically validate our approach on the benchmark affine-invariant classification task, where we achieve 30\% improvement in accuracy against conventional {CNNs} while outperforming most {CapsNets}. As further illustration of the generality of our framework, we train a homography-convolutional model which achieves superior robustness on a homography-perturbed dataset, where {CapsNet} results degrade.},
	publisher = {{arXiv}},
	author = {{MacDonald}, Lachlan Ewen and Ramasinghe, Sameera and Lucey, Simon},
	urldate = {2024-04-01},
	date = {2022-03},
	doi = {10.48550/arXiv.2111.08251},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/LRJ4F8L6/MacDonald et al. - 2022 - Enabling equivariance for arbitrary Lie groups.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/SXJ8RG9A/2111.html:text/html},
}

@misc{finzi_practical_2021,
	title = {A Practical Method for Constructing Equivariant Multilayer Perceptrons for Arbitrary Matrix Groups},
	url = {http://arxiv.org/abs/2104.09459},
	abstract = {Symmetries and equivariance are fundamental to the generalization of neural networks on domains such as images, graphs, and point clouds. Existing work has primarily focused on a small number of groups, such as the translation, rotation, and permutation groups. In this work we provide a completely general algorithm for solving for the equivariant layers of matrix groups. In addition to recovering solutions from other works as special cases, we construct multilayer perceptrons equivariant to multiple groups that have never been tackled before, including \{{\textbackslash}textbackslashmathrm\{O\}(1,3){\textbackslash}, \{{\textbackslash}textbackslashmathrm\{O\}(5){\textbackslash}, \{{\textbackslash}textbackslashmathrm\{Sp\}(n){\textbackslash}, and the Rubik's cube group. Our approach outperforms non-equivariant baselines, with applications to particle physics and dynamical systems. We release our software library to enable researchers to construct equivariant layers for arbitrary matrix groups.},
	publisher = {{arXiv}},
	author = {Finzi, Marc and Welling, Max and Wilson, Andrew Gordon},
	urldate = {2024-04-01},
	date = {2021-04},
	doi = {10.48550/arXiv.2104.09459},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Dynamical Systems},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/4U3QKKDC/Finzi et al. - 2021 - A Practical Method for Constructing Equivariant Mu.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/SY5UJI9S/2104.html:text/html},
}

@article{basu_grepsnet_2023,
	title = {{GRepsNet}: A Simple Equivariant Network for Arbitrary Matrix Groups},
	url = {https://openreview.net/forum?id=tzpXhoNel1},
	shorttitle = {{GRepsNet}},
	abstract = {Group equivariance is a strong inductive bias useful in a wide range of domains including images, point clouds, dynamical systems, and partial differential equations ({PDEs}). But constructing efficient equivariant networks for general groups and domains is difficult. Recent work by Finzi et al. (2021) directly solves the equivariance constraint for arbitrary matrix groups to obtain equivariant {MLPs} ({EMLPs}). However, this method does not scale well and scaling is crucial to get the best from deep learning. This necessitates the design of group equivariant networks for general domains and groups that are simple and scalable. To this end, we introduce Group Representation Networks ({GRepsNets}), a simple equivariant network for arbitrary matrix groups. The key intuition for our design is that using tensor representations in the hidden layers of a neural network along with appropriate mixing of various representations can lead to expressive equivariant networks, which we confirm empirically. We find {GRepsNet} to be competitive to {EMLP} on several tasks with group symmetries such as O(5), O(1, 3), and O(3) with scalars, vectors, and second-order tensors as data types. To illustrate the simplicity and generality of our network, we also use it for image classification with {MLP}-mixers, predicting N-body dynamics using message passing neural networks ({MPNNs}), and for solving {PDEs} using Fourier neural operators ({FNOs}). Surprisingly, we find that using simple first-order representations itself can yield benefits of group equivariance without additional changes in the architecture. Finally, we illustrate how higher-order tensor representations can be used for group equivariant finetuning that outperforms the existing equivariant finetuning method Basu et al. (2023b).},
	author = {Basu, Sourya and Lohit, Suhas and Brand, Matthew},
	urldate = {2024-04-01},
	date = {2023-10},
	langid = {english},
	file = {Full Text PDF:/home/maxi/Zotero/storage/9DRZEQA8/Basu et al. - 2023 - GRepsNet A Simple Equivariant Network for Arbitra.pdf:application/pdf},
}

@misc{basu_g-repsnet_2024,
	title = {G-{RepsNet}: A Fast and General Construction of Equivariant Networks for Arbitrary Matrix Groups},
	url = {http://arxiv.org/abs/2402.15413},
	shorttitle = {G-{RepsNet}},
	abstract = {Group equivariance is a strong inductive bias useful in a wide range of deep learning tasks. However, constructing efficient equivariant networks for general groups and domains is difficult. Recent work by Finzi et al. (2021) directly solves the equivariance constraint for arbitrary matrix groups to obtain equivariant {MLPs} ({EMLPs}). But this method does not scale well and scaling is crucial in deep learning. Here, we introduce Group Representation Networks (G-{RepsNets}), a lightweight equivariant network for arbitrary matrix groups with features represented using tensor polynomials. The key intuition for our design is that using tensor representations in the hidden layers of a neural network along with simple inexpensive tensor operations can lead to expressive universal equivariant networks. We find G-{RepsNet} to be competitive to {EMLP} on several tasks with group symmetries such as O(5), O(1, 3), and O(3) with scalars, vectors, and second-order tensors as data types. On image classification tasks, we find that G-{RepsNet} using second-order representations is competitive and often even outperforms sophisticated state-of-the-art equivariant models such as {GCNNs} (Cohen \& Welling, 2016a) and E(2)-{CNNs} (Weiler \& Cesa, 2019). To further illustrate the generality of our approach, we show that G-{RepsNet} is competitive to G-{FNO} (Helwig et al., 2023) and {EGNN} (Satorras et al., 2021) on N-body predictions and solving {PDEs}, respectively, while being efficient.},
	publisher = {{arXiv}},
	author = {Basu, Sourya and Lohit, Suhas and Brand, Matthew},
	urldate = {2024-04-02},
	date = {2024-02},
	doi = {10.48550/arXiv.2402.15413},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/YDUS9EZD/Basu et al. - 2024 - G-RepsNet A Fast and General Construction of Equi.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/6GNZKA9P/2402.html:text/html},
}

@misc{batatia_general_2023,
	title = {A General Framework for Equivariant Neural Networks on Reductive Lie Groups},
	url = {http://arxiv.org/abs/2306.00091},
	abstract = {Reductive Lie Groups, such as the orthogonal groups, the Lorentz group, or the unitary groups, play essential roles across scientific fields as diverse as high energy physics, quantum mechanics, quantum chromodynamics, molecular dynamics, computer vision, and imaging. In this paper, we present a general Equivariant Neural Network architecture capable of respecting the symmetries of the finite-dimensional representations of any reductive Lie Group G. Our approach generalizes the successful {ACE} and {MACE} architectures for atomistic point clouds to any data equivariant to a reductive Lie group action. We also introduce the lie-nn software library, which provides all the necessary tools to develop and implement such general G-equivariant neural networks. It implements routines for the reduction of generic tensor products of representations into irreducible representations, making it easy to apply our architecture to a wide range of problems and groups. The generality and performance of our approach are demonstrated by applying it to the tasks of top quark decay tagging (Lorentz group) and shape recognition (orthogonal group).},
	publisher = {{arXiv}},
	author = {Batatia, Ilyes and Geiger, Mario and Munoz, Jose and Smidt, Tess and Silberman, Lior and Ortner, Christoph},
	urldate = {2024-04-05},
	date = {2023-05},
	doi = {10.48550/arXiv.2306.00091},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, High Energy Physics - Theory},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/8UF5CQVF/Batatia et al. - 2023 - A General Framework for Equivariant Neural Network.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/LG4FYZ9D/2306.html:text/html},
}

@misc{bogatskiy_lorentz_2020,
	title = {Lorentz Group Equivariant Neural Network for Particle Physics},
	url = {http://arxiv.org/abs/2006.04780},
	abstract = {We present a neural network architecture that is fully equivariant with respect to transformations under the Lorentz group, a fundamental symmetry of space and time in physics. The architecture is based on the theory of the finite-dimensional representations of the Lorentz group and the equivariant nonlinearity involves the tensor product. For classification tasks in particle physics, we demonstrate that such an equivariant architecture leads to drastically simpler models that have relatively few learnable parameters and are much more physically interpretable than leading approaches that use {CNNs} and point cloud approaches. The competitive performance of the network is demonstrated on a public classification dataset [27] for tagging top quark decays given energy-momenta of jet constituents produced in proton-proton collisions.},
	publisher = {{arXiv}},
	author = {Bogatskiy, Alexander and Anderson, Brandon and Offermann, Jan T. and Roussi, Marwah and Miller, David W. and Kondor, Risi},
	urldate = {2024-04-05},
	date = {2020-06},
	doi = {10.48550/arXiv.2006.04780},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, High Energy Physics - Experiment, High Energy Physics - Phenomenology, Physics - Computational Physics},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/Q4ADHBGD/Bogatskiy et al. - 2020 - Lorentz Group Equivariant Neural Network for Parti.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/J4JGMJ9G/2006.html:text/html},
}

@misc{noauthor_httpswwwcisupennedutextasciitildejeaninterp-simpdf_nodate,
	title = {https://www.cis.upenn.edu/{\textbackslash}textasciitildejean/interp-{SIM}.pdf},
	url = {https://www.cis.upenn.edu/~jean/interp-SIM.pdf},
	urldate = {2024-04-10},
}

@misc{ruhe_geometric_2023,
	title = {Geometric Clifford Algebra Networks},
	url = {http://arxiv.org/abs/2302.06594},
	abstract = {We propose Geometric Clifford Algebra Networks ({GCANs}) for modeling dynamical systems. {GCANs} are based on symmetry group transformations using geometric (Clifford) algebras. We first review the quintessence of modern (plane-based) geometric algebra, which builds on isometries encoded as elements of the \{{\textbackslash}textbackslashmathrm\{Pin\}(p,q,r){\textbackslash} group. We then propose the concept of group action layers, which linearly combine object transformations using pre-specified group actions. Together with a new activation and normalization scheme, these layers serve as adjustable \{{\textbackslash}textbackslashtextit\{geometric templates\}{\textbackslash} that can be refined via gradient descent. Theoretical advantages are strongly reflected in the modeling of three-dimensional rigid body transformations as well as large-scale fluid dynamics simulations, showing significantly improved performance over traditional methods.},
	publisher = {{arXiv}},
	author = {Ruhe, David and Gupta, Jayesh K. and de Keninck, Steven and Welling, Max and Brandstetter, Johannes},
	urldate = {2024-04-14},
	date = {2023-05},
	doi = {10.48550/arXiv.2302.06594},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/VBP2CDCR/Ruhe et al. - 2023 - Geometric Clifford Algebra Networks.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/QF7TIV74/2302.html:text/html},
}

@misc{ruhe_clifford_2023,
	title = {Clifford Group Equivariant Neural Networks},
	url = {http://arxiv.org/abs/2305.11141},
	abstract = {We introduce Clifford Group Equivariant Neural Networks: a novel approach for constructing \{{\textbackslash}textbackslashmathrm\{O\}(n){\textbackslash}- and \{{\textbackslash}textbackslashmathrm\{E\}(n){\textbackslash}-equivariant models. We identify and study the \{{\textbackslash}textbackslashtextit\{Clifford group\}{\textbackslash}, a subgroup inside the Clifford algebra tailored to achieve several favorable properties. Primarily, the group's action forms an orthogonal automorphism that extends beyond the typical vector space to the entire Clifford algebra while respecting the multivector grading. This leads to several non-equivalent subrepresentations corresponding to the multivector decomposition. Furthermore, we prove that the action respects not just the vector space structure of the Clifford algebra but also its multiplicative structure, i.e., the geometric product. These findings imply that every polynomial in multivectors, An advantage worth mentioning is that we obtain expressive layers that can elegantly generalize to inner-product spaces of any dimension. We demonstrate, notably from a single core implementation, state-of-the-art performance on several distinct tasks, including a three-dimensional {\textbackslash}n{\textbackslash}-body experiment, a four-dimensional Lorentz-equivariant high-energy physics experiment, and a five-dimensional convex hull experiment.},
	publisher = {{arXiv}},
	author = {Ruhe, David and Brandstetter, Johannes and Forré, Patrick},
	urldate = {2024-04-14},
	date = {2023-10},
	doi = {10.48550/arXiv.2305.11141},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/R78Y97GY/Ruhe et al. - 2023 - Clifford Group Equivariant Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/N5PBQ6TM/2305.html:text/html},
}

@misc{zhdanov_clifford-steerable_2024,
	title = {Clifford-Steerable Convolutional Neural Networks},
	url = {http://arxiv.org/abs/2402.14730},
	abstract = {We present Clifford-Steerable Convolutional Neural Networks ({CS}-{CNNs}), a novel class of \{{\textbackslash}textbackslashmathrm\{E\}(p, q){\textbackslash}-equivariant {CNNs}. {CS}-{CNNs} process multivector fields on pseudo-Euclidean spaces \{{\textbackslash}textbackslashmathbb\{R\}ˆ\{p,q\}{\textbackslash}. They cover, for instance, \{{\textbackslash}textbackslashmathrm\{E\}(3){\textbackslash}-equivariance on \{{\textbackslash}textbackslashmathbb\{R\}ˆ3{\textbackslash} and Poincar{\textbackslash}textbackslash'e-equivariance on Minkowski spacetime \{{\textbackslash}textbackslashmathbb\{R\}ˆ\{1,3\}{\textbackslash}. Our approach is based on an implicit parametrization of \{{\textbackslash}textbackslashmathrm\{O\}(p,q){\textbackslash}-steerable kernels via Clifford group equivariant neural networks. We significantly and consistently outperform baseline methods on fluid dynamics as well as relativistic electrodynamics forecasting tasks.},
	publisher = {{arXiv}},
	author = {Zhdanov, Maksim and Ruhe, David and Weiler, Maurice and Lucic, Ana and Brandstetter, Johannes and Forré, Patrick},
	urldate = {2024-04-15},
	date = {2024-02},
	doi = {10.48550/arXiv.2402.14730},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/VLPAL9QR/Zhdanov et al. - 2024 - Clifford-Steerable Convolutional Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/94GKK835/2402.html:text/html},
}

@misc{ruhe_c2c_2023,
	title = {C2C 3: Geometric Clifford Algebra Networks},
	url = {https://davidruhe.github.io/2023/06/06/ga-layers.html},
	shorttitle = {C2C 3},
	abstract = {In this third post of the series, we further explore the geometric bias that Clifford algebras induce. After studying modern plane-based geometric algebra, we generalize the successful rotational layer to any (Euclidean) group action. Thereby, we discourage transformations that are geometrically ungrounded. The resulting networks can be regarded as geometric templates. We discuss the resulting networks on a large-scale shallow-water equations experiment.},
	author = {Ruhe, David},
	urldate = {2024-04-15},
	date = {2023-06},
	langid = {english},
	note = {Publication Title: David Ruhe},
	file = {Snapshot:/home/maxi/Zotero/storage/3IZ2TFCP/ga-layers.html:text/html},
}

@misc{romero_learning_2023,
	title = {Learning Partial Equivariances from Data},
	url = {http://arxiv.org/abs/2110.10211},
	abstract = {Group Convolutional Neural Networks (G-{CNNs}) constrain learned features to respect the symmetries in the selected group, and lead to better generalization when these symmetries appear in the data. If this is not the case, however, equivariance leads to overly constrained models and worse performance. Frequently, transformations occurring in data can be better represented by a subset of a group than by a group as a whole, e.g., rotations in {\textbackslash}[-90ˆ\{{\textbackslash}textbackslashcirc\}, 90ˆ\{{\textbackslash}textbackslashcirc\}]{\textbackslash}. In such cases, a model that respects equivariance \{{\textbackslash}textbackslashtextit\{partially\}{\textbackslash} is better suited to represent the data. In addition, relevant transformations may differ for low and high-level features. For instance, full rotation equivariance is useful to describe edge orientations in a face, but partial rotation equivariance is better suited to describe face poses relative to the camera. In other words, the optimal level of equivariance may differ per layer. In this work, we introduce \{{\textbackslash}textbackslashtextit\{Partial G-{CNNs}\}{\textbackslash}: G-{CNNs} able to learn layer-wise levels of partial and full equivariance to discrete, continuous groups and combinations thereof as part of training. Partial G-{CNNs} retain full equivariance when beneficial, e.g., for rotated {MNIST}, but adjust it whenever it becomes harmful, e.g., for classification of 6 / 9 digits or natural images. We empirically show that partial G-{CNNs} pair G-{CNNs} when full equivariance is advantageous, and outperform them otherwise.},
	publisher = {{arXiv}},
	author = {Romero, David W. and Lohit, Suhas},
	urldate = {2024-04-19},
	date = {2023-01},
	doi = {10.48550/arXiv.2110.10211},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/95AMEFCV/Romero and Lohit - 2023 - Learning Partial Equivariances from Data.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/Q8T4I745/2110.html:text/html},
}

@article{bekkers_template_2018,
	title = {Template Matching via Densities on the Roto-Translation Group},
	volume = {40},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{OAPA}.html},
	issn = {0162-8828, 2160-9292},
	url = {http://ieeexplore.ieee.org/document/7864477/},
	doi = {10.1109/TPAMI.2017.2652452},
	pages = {452--466},
	number = {2},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Bekkers, Erik Johannes and Loog, Marco and Romeny, Bart M. Ter Haar and Duits, Remco},
	urldate = {2024-04-21},
	date = {2018-02},
	keywords = {{toRead}},
}

@misc{weiler_learning_2018,
	title = {Learning Steerable Filters for Rotation Equivariant {CNNs}},
	url = {http://arxiv.org/abs/1711.07289},
	abstract = {In many machine learning tasks it is desirable that a model's prediction transforms in an equivariant way under transformations of its input. Convolutional neural networks ({CNNs}) implement translational equivariance by construction; for other transformations, however, they are compelled to learn the proper mapping. In this work, we develop Steerable Filter {CNNs} ({SFCNNs}) which achieve joint equivariance under translations and rotations by design. The proposed architecture employs steerable filters to efficiently compute orientation dependent responses for many orientations without suffering interpolation artifacts from filter rotation. We utilize group convolutions which guarantee an equivariant mapping. In addition, we generalize He's weight initialization scheme to filters which are defined as a linear combination of a system of atomic filters. Numerical experiments show a substantial enhancement of the sample complexity with a growing number of sampled filter orientations and confirm that the network generalizes learned patterns over orientations. The proposed approach achieves state-of-the-art on the rotated {MNIST} benchmark and on the {ISBI} 2012 2D {EM} segmentation challenge.},
	publisher = {{arXiv}},
	author = {Weiler, Maurice and Hamprecht, Fred A. and Storath, Martin},
	urldate = {2024-04-21},
	date = {2018-03},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, {toRead}},
}

@misc{diamond_unrolled_2018,
	title = {Unrolled Optimization with Deep Priors},
	url = {http://arxiv.org/abs/1705.08041},
	abstract = {A broad class of problems at the core of computational imaging, sensing, and low-level computer vision reduces to the inverse problem of extracting latent images that follow a prior distribution, from measurements taken under a known physical image formation model. Traditionally, hand-crafted priors along with iterative optimization methods have been used to solve such problems. In this paper we present unrolled optimization with deep priors, a principled framework for infusing knowledge of the image formation into deep networks that solve inverse problems in imaging, inspired by classical iterative methods. We show that instances of the framework outperform the state-of-the-art by a substantial margin for a wide variety of imaging problems, such as denoising, deblurring, and compressed sensing magnetic resonance imaging ({MRI}). Moreover, we conduct experiments that explain how the framework is best used and why it outperforms previous methods.},
	publisher = {{arXiv}},
	author = {Diamond, Steven and Sitzmann, Vincent and Heide, Felix and Wetzstein, Gordon},
	urldate = {2024-04-24},
	date = {2018-12},
	doi = {10.48550/arXiv.1705.08041},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/45QXI5F2/Diamond et al. - 2018 - Unrolled Optimization with Deep Priors.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/UKIKJDVF/1705.html:text/html},
}

@misc{cole_analysis_2020,
	title = {Analysis of Deep Complex-Valued Convolutional Neural Networks for {MRI} Reconstruction},
	url = {http://arxiv.org/abs/2004.01738},
	abstract = {Many real-world signal sources are complex-valued, having real and imaginary components. However, the vast majority of existing deep learning platforms and network architectures do not support the use of complex-valued data. {MRI} data is inherently complex-valued, so existing approaches discard the richer algebraic structure of the complex data. In this work, we investigate end-to-end complex-valued convolutional neural networks - specifically, for image reconstruction in lieu of two-channel real-valued networks. We apply this to magnetic resonance imaging reconstruction for the purpose of accelerating scan times and determine the performance of various promising complex-valued activation functions. We find that complex-valued {CNNs} with complex-valued convolutions provide superior reconstructions compared to real-valued convolutions with the same number of trainable parameters, over a variety of network architectures and datasets.},
	publisher = {{arXiv}},
	author = {Cole, Elizabeth K. and Cheng, Joseph Y. and Pauly, John M. and Vasanawala, Shreyas S.},
	urldate = {2024-04-24},
	date = {2020-05},
	doi = {10.48550/arXiv.2004.01738},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Physics - Medical Physics},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/B74UMJ5K/Cole et al. - 2020 - Analysis of Deep Complex-Valued Convolutional Neur.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/G6IJ9SSA/2004.html:text/html},
}

@misc{noauthor_httpswwwisca-archiveorginterspeech_2020nakashika20_interspeechpdf_nodate-1,
	title = {https://www.isca-archive.org/interspeech\_2020/nakashika20\_interspeech.pdf},
	url = {https://www.isca-archive.org/interspeech_2020/nakashika20_interspeech.pdf},
	urldate = {2024-05-04},
}

@article{pallua_future_2020,
	title = {The future of pathology is digital},
	volume = {216},
	issn = {1618-0631},
	doi = {10.1016/j.prp.2020.153040},
	abstract = {Information, archives, and intelligent artificial systems are part of everyday life in modern medicine. They already support medical staff by mapping their workflows with shared availability of cases' referral information, as needed for example, by the pathologist, and this support will be increased in the future even more. In radiology, established standards define information models, data transmission mechanisms, and workflows. Other disciplines, such as pathology, cardiology, and radiation therapy, now define further demands in addition to these established standards. Pathology may have the highest technical demands on the systems, with very complex workflows, and the digitization of slides generating enormous amounts of data up to Gigabytes per biopsy. This requires enormous amounts of data to be generated per biopsy, up to the gigabyte range. Digital pathology allows a change from classical histopathological diagnosis with microscopes and glass slides to virtual microscopy on the computer, with multiple tools using artificial intelligence and machine learning to support pathologists in their future work.},
	pages = {153040},
	number = {9},
	journaltitle = {Pathology, Research and Practice},
	shortjournal = {Pathol Res Pract},
	author = {Pallua, J. D. and Brunner, A. and Zelger, B. and Schirmer, M. and Haybaeck, J.},
	date = {2020-09},
	pmid = {32825928},
	keywords = {Pathology, Artifical intelligence, Artificial Intelligence, Computer-assisted diagnosis, Digital pathology, Humans, Image Interpretation, Computer-Assisted, Image Processing, Computer-Assisted, Management, Pathologists, Quality, Safety, Teaching, Telemedicine, Workflow},
}

@article{kiran_digital_nodate,
	title = {Digital Pathology: Transforming Diagnosis in the Digital Age},
	volume = {15},
	issn = {2168-8184},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10547926/},
	doi = {10.7759/cureus.44620},
	shorttitle = {Digital Pathology},
	abstract = {In the context of rapid technological advancements, the narrative review titled "Digital Pathology: Transforming Diagnosis in the Digital Age" explores the significant impact of digital pathology in reshaping diagnostic approaches. This review delves into the various effects of the field, including remote consultations and artificial intelligence ({AI})-assisted analysis, revealing the ongoing transformation taking place. The investigation explores the process of digitizing traditional glass slides, which aims to improve accessibility and facilitate sharing. Additionally, it addresses the complexities associated with data security and standardization challenges. Incorporating {AI} enhances pathologists' diagnostic capabilities and accelerates analytical procedures. Furthermore, the review highlights the growing importance of collaborative networks facilitating global knowledge sharing. It also emphasizes the significant impact of this technology on medical education and patient care. This narrative review aims to provide an overview of digital pathology's transformative and innovative potential, highlighting its disruptive nature in reshaping diagnostic practices.},
	pages = {e44620},
	number = {9},
	journaltitle = {Cureus},
	shortjournal = {Cureus},
	author = {Kiran, Nfn and Sapna, {FNU} and Kiran, {FNU} and Kumar, Deepak and Raja, {FNU} and Shiwlani, Sheena and Paladini, Antonella and Sonam, {FNU} and Bendari, Ahmed and Perkash, Raja Sandeep and Anjali, {FNU} and Varrassi, Giustino},
	urldate = {2024-05-09},
	pmid = {37799211},
	pmcid = {PMC10547926},
	file = {PubMed Central Full Text PDF:/home/maxi/Zotero/storage/GLWVFB9D/Kiran et al. - Digital Pathology Transforming Diagnosis in the D.pdf:application/pdf},
}

@article{sung_global_2021-1,
	title = {Global Cancer Statistics 2020: {GLOBOCAN} Estimates of Incidence and Mortality Worldwide for 36 Cancers in 185 Countries},
	volume = {71},
	issn = {1542-4863},
	doi = {10.3322/caac.21660},
	shorttitle = {Global Cancer Statistics 2020},
	abstract = {This article provides an update on the global cancer burden using the {GLOBOCAN} 2020 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer. Worldwide, an estimated 19.3 million new cancer cases (18.1 million excluding nonmelanoma skin cancer) and almost 10.0 million cancer deaths (9.9 million excluding nonmelanoma skin cancer) occurred in 2020. Female breast cancer has surpassed lung cancer as the most commonly diagnosed cancer, with an estimated 2.3 million new cases (11.7\%), followed by lung (11.4\%), colorectal (10.0 \%), prostate (7.3\%), and stomach (5.6\%) cancers. Lung cancer remained the leading cause of cancer death, with an estimated 1.8 million deaths (18\%), followed by colorectal (9.4\%), liver (8.3\%), stomach (7.7\%), and female breast (6.9\%) cancers. Overall incidence was from 2-fold to 3-fold higher in transitioned versus transitioning countries for both sexes, whereas mortality varied {\textless}2-fold for men and little for women. Death rates for female breast and cervical cancers, however, were considerably higher in transitioning versus transitioned countries (15.0 vs 12.8 per 100,000 and 12.4 vs 5.2 per 100,000, respectively). The global cancer burden is expected to be 28.4 million cases in 2040, a 47\% rise from 2020, with a larger increase in transitioning (64\% to 95\%) versus transitioned (32\% to 56\%) countries due to demographic changes, although this may be further exacerbated by increasing risk factors associated with globalization and a growing economy. Efforts to build a sustainable infrastructure for the dissemination of cancer prevention measures and provision of cancer care in transitioning countries is critical for global cancer control.},
	pages = {209--249},
	number = {3},
	journaltitle = {{CA}: a cancer journal for clinicians},
	shortjournal = {{CA} Cancer J Clin},
	author = {Sung, Hyuna and Ferlay, Jacques and Siegel, Rebecca L. and Laversanne, Mathieu and Soerjomataram, Isabelle and Jemal, Ahmedin and Bray, Freddie},
	date = {2021-05},
	pmid = {33538338},
	keywords = {Humans, Africa, Americas, Asia, burden, cancer, Databases, Factual, Developed Countries, Developing Countries, epidemiology, Europe, Female, Global Health, incidence, Incidence, Internationality, Male, mortality, Neoplasms, Oceania, Population Dynamics, Risk Factors, Sex Distribution},
}

@article{baxi_digital_2022,
	title = {Digital pathology and artificial intelligence in translational medicine and clinical practice},
	volume = {35},
	issn = {1530-0285},
	doi = {10.1038/s41379-021-00919-2},
	abstract = {Traditional pathology approaches have played an integral role in the delivery of diagnosis, semi-quantitative or qualitative assessment of protein expression, and classification of disease. Technological advances and the increased focus on precision medicine have recently paved the way for the development of digital pathology-based approaches for quantitative pathologic assessments, namely whole slide imaging and artificial intelligence ({AI})-based solutions, allowing us to explore and extract information beyond human visual perception. Within the field of immuno-oncology, the application of such methodologies in drug development and translational research have created invaluable opportunities for deciphering complex pathophysiology and the discovery of novel biomarkers and drug targets. With an increasing number of treatment options available for any given disease, practitioners face the growing challenge of selecting the most appropriate treatment for each patient. The ever-increasing utilization of {AI}-based approaches substantially expands our understanding of the tumor microenvironment, with digital approaches to patient stratification and selection for diagnostic assays supporting the identification of the optimal treatment regimen based on patient profiles. This review provides an overview of the opportunities and limitations around implementing {AI}-based methods in biomarker discovery and patient selection and discusses how advances in digital pathology and {AI} should be considered in the current landscape of translational medicine, touching on challenges this technology may face if adopted in clinical settings. The traditional role of pathologists in delivering accurate diagnoses or assessing biomarkers for companion diagnostics may be enhanced in precision, reproducibility, and scale by {AI}-powered analysis tools.},
	pages = {23--32},
	number = {1},
	journaltitle = {Modern Pathology: An Official Journal of the United States and Canadian Academy of Pathology, Inc},
	shortjournal = {Mod Pathol},
	author = {Baxi, Vipul and Edwards, Robin and Montalto, Michael and Saha, Saurabh},
	date = {2022-01},
	pmid = {34611303},
	pmcid = {PMC8491759},
	keywords = {Pathology, Artificial Intelligence, Humans, Algorithms, Biomarkers, Practice Patterns, Physicians', Translational Science, Biomedical},
	file = {Full Text:/home/maxi/Zotero/storage/V26FNFMK/Baxi et al. - 2022 - Digital pathology and artificial intelligence in t.pdf:application/pdf},
}

@book{chatterjee_machine_2021,
	title = {Machine Learning and Its Application: A Quick Guide for Beginners},
	isbn = {978-1-68108-940-9},
	url = {https://www.eurekaselect.com/199239/volume/1},
	shorttitle = {Machine Learning and Its Application},
	publisher = {{BENTHAM} {SCIENCE} {PUBLISHERS}},
	author = {Chatterjee, Indranath},
	urldate = {2024-05-09},
	date = {2021-12-22},
	langid = {english},
	doi = {10.2174/97816810894091210101},
	file = {Chatterjee - 2021 - Machine Learning and Its Application A Quick Guid.pdf:/home/maxi/Zotero/storage/39692SG9/Chatterjee - 2021 - Machine Learning and Its Application A Quick Guid.pdf:application/pdf},
}

@misc{lim_what_2022,
	title = {What is an equivariant neural network?},
	url = {http://arxiv.org/abs/2205.07362},
	doi = {10.48550/arXiv.2205.07362},
	abstract = {We explain equivariant neural networks, a notion underlying breakthroughs in machine learning from deep convolutional neural networks for computer vision to {AlphaFold} 2 for protein structure prediction, without assuming knowledge of equivariance or neural networks. The basic mathematical ideas are simple but are often obscured by engineering complications that come with practical realizations. We extract and focus on the mathematical aspects, and limit ourselves to a cursory treatment of the engineering issues at the end.},
	number = {{arXiv}:2205.07362},
	publisher = {{arXiv}},
	author = {Lim, Lek-Heng and Nelson, Bradley J.},
	urldate = {2024-05-09},
	date = {2022-11-16},
	eprinttype = {arxiv},
	eprint = {2205.07362 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, I.2.6, Mathematics - Representation Theory},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/M8RZGVTA/Lim and Nelson - 2022 - What is an equivariant neural network.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/PZTWL85D/2205.html:text/html},
}

@misc{cohen_steerable_2016,
	title = {Steerable {CNNs}},
	url = {http://arxiv.org/abs/1612.08498},
	doi = {10.48550/arXiv.1612.08498},
	abstract = {It has long been recognized that the invariance and equivariance properties of a representation are critically important for success in many vision tasks. In this paper we present Steerable Convolutional Neural Networks, an efficient and flexible class of equivariant convolutional networks. We show that steerable {CNNs} achieve state of the art results on the {CIFAR} image classification benchmark. The mathematical theory of steerable representations reveals a type system in which any steerable representation is a composition of elementary feature types, each one associated with a particular kind of symmetry. We show how the parameter cost of a steerable filter bank depends on the types of the input and output features, and show how to use this knowledge to construct {CNNs} that utilize parameters effectively.},
	number = {{arXiv}:1612.08498},
	publisher = {{arXiv}},
	author = {Cohen, Taco S. and Welling, Max},
	urldate = {2024-05-09},
	date = {2016-12-26},
	eprinttype = {arxiv},
	eprint = {1612.08498 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/TJUNYY3K/Cohen and Welling - 2016 - Steerable CNNs.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/TSFQQQ2Y/1612.html:text/html},
}

@article{freeman_design_1991,
	title = {The design and use of steerable filters},
	volume = {13},
	issn = {1939-3539},
	url = {https://ieeexplore.ieee.org/document/93808},
	doi = {10.1109/34.93808},
	abstract = {The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation. Steerable filters may be designed in quadrature pairs to allow adaptive control over phase as well as orientation. The authors show how to design and steer the filters and present examples of their use in the analysis of orientation and phase, angularly adaptive filtering, edge detection, and shape from shading. One can also build a self-similar steerable pyramid representation. The same concepts can be generalized to the design of 3-D steerable filters.{\textless}{\textgreater}},
	pages = {891--906},
	number = {9},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Freeman, W.T. and Adelson, E.H.},
	urldate = {2024-05-09},
	date = {1991-09},
	note = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Adaptive control, Adaptive filters, Image analysis, Image edge detection, Image motion analysis, Image processing, Image sequence analysis, Image texture analysis, Nonlinear filters, Shape},
	file = {IEEE Xplore Abstract Record:/home/maxi/Zotero/storage/3FTMMHV6/93808.html:text/html},
}

@online{veeling_rotation_2018,
	title = {Rotation Equivariant {CNNs} for Digital Pathology},
	url = {https://arxiv.org/abs/1806.03962v1},
	abstract = {We propose a new model for digital pathology segmentation, based on the observation that histopathology images are inherently symmetric under rotation and reflection. Utilizing recent findings on rotation equivariant {CNNs}, the proposed model leverages these symmetries in a principled manner. We present a visual analysis showing improved stability on predictions, and demonstrate that exploiting rotation equivariance significantly improves tumor detection performance on a challenging lymph node metastases dataset. We further present a novel derived dataset to enable principled comparison of machine learning models, in combination with an initial benchmark. Through this dataset, the task of histopathology diagnosis becomes accessible as a challenging benchmark for fundamental machine learning research.},
	titleaddon = {{arXiv}.org},
	author = {Veeling, Bastiaan S. and Linmans, Jasper and Winkens, Jim and Cohen, Taco and Welling, Max},
	urldate = {2024-05-10},
	date = {2018-06-08},
	langid = {english},
	file = {Full Text PDF:/home/maxi/Zotero/storage/TQBQRDFP/Veeling et al. - 2018 - Rotation Equivariant CNNs for Digital Pathology.pdf:application/pdf},
}

@inproceedings{li_dynamic_2020,
	title = {A Dynamic Group Equivariant Convolutional Networks for Medical Image Analysis},
	url = {https://ieeexplore.ieee.org/document/9313601},
	doi = {10.1109/BIBM49941.2020.9313601},
	abstract = {Group equivariant Convolutional Neural Networks (G-{CNNs}) has led to big empirical success in the medical domain, one fundamental assumption is that equivariance provides a powerful inductive bias for medical images. By leveraging concepts from group representation theory, we can generalize vanilla Convolutional Neural Networks ({CNNs}) to G-{CNN}. Currently, although embedding an arbitrary equivariance to {CNNs} can learn powerful disentangled representations in a higher dimensional domain, they lack explicit means to learn meaningful relationships among the equivariant convolutional kernels. In this paper, we propose a generalization of the dynamic convolutional method, named as dynamic group equivariant convolution, to strengthen the relationships and increase model capability by aggregating multiple group convolutional kernels via attention. Meanwhile, we generalize attention to an equivariant one to preserve equivariant of dynamic group convolution. In our approach, this leads to a flexible framework that enables a dynamic convolutional in G-{CNNs} by means of a dynamic routing layer expansions. We demonstrate that breast tumor classification is substantial improvements when compared to a recent baseline architecture.},
	eventtitle = {2020 {IEEE} International Conference on Bioinformatics and Biomedicine ({BIBM})},
	pages = {1056--1062},
	booktitle = {2020 {IEEE} International Conference on Bioinformatics and Biomedicine ({BIBM})},
	author = {Li, Yan and Cao, Guitao and Cao, Wenming},
	urldate = {2024-05-10},
	date = {2020-12},
	keywords = {Attention, Biomedical imaging, Convolution, Convolutional neural networks, Deep learning, Dynamic group convolution, Equivariance, Group Convolutional neural networks, Kernel, Routing, Visual systems, Visualization},
	file = {IEEE Xplore Abstract Record:/home/maxi/Zotero/storage/PIAEPL7G/9313601.html:text/html},
}

@online{noauthor_wma_nodate,
	title = {{WMA} - The World Medical Association-Declaración de Helsinki de la {AMM} – Principios éticos para las investigaciones médicas en seres humanos},
	url = {https://www.wma.net/es/policies-post/declaracion-de-helsinki-de-la-amm-principios-eticos-para-las-investigaciones-medicas-en-seres-humanos/},
	urldate = {2024-05-10},
	langid = {spanish},
	file = {Snapshot:/home/maxi/Zotero/storage/CECSV68N/declaracion-de-helsinki-de-la-amm-principios-eticos-para-las-investigaciones-medicas-en-seres-h.html:text/html},
}

@report{council_for_international_organizations_of_medical_sciences_cioms_international_2016,
	title = {International Ethical Guidelines for Health-related Research involving Humans},
	url = {https://cioms.ch/publications/product/international-ethical-guidelines-for-health-related-research-involving-humans/},
	abstract = {Progress towards a world where all can enjoy optimal health and health care is crucially dependent on all kinds of research including research involving humans. Involving humans in medical research is necessary to improve the knowledge base on which medicine should be based. At the same time, individuals participating in health-related research have individual human rights and have a right to be protected against the risks that research may bring to them. The tension between these two considerations has led the medical community to endorse ethical guidelines for health-related research. Research Ethics Committees can use these guidelines to evaluate whether a given research protocol is ethically acceptable or not. -- In the late 1970s, {CIOMS} set out, in cooperation with {WHO}, to prepare guidelines to indicate how the ethical principles set forth in the Declaration of Helsinki of the World Medical Association, could be effectively applied, particularly in low-resource settings, given their socio-economic circumstances, laws and regulations, and executive and administrative arrangements. Since then, revised editions of the {CIOMS} ethical guidelines were published in 1993 and 2002. New developments in research prompted {CIOMS} to again revise their ethical guidelines. The result is available in this publication. -- In the 2016 version of the ethical Guidelines, {CIOMS} provides answers to a number of pressing issues in research ethics. The Council does so by stressing the need for research having scientific and social value, by providing special guidelines for health-related research in low-resource settings, by detailing the provisions for involving vulnerable groups in research and for describing under what conditions biological samples and health-related data can be used for research. In providing this revised version, {CIOMS} hopes to ensure that the ethical Guidelines remain a living document that provides reasoned conditions for research in order to meet the challenges of modern research.},
	institution = {Council for International Organizations of Medical Sciences ({CIOMS})},
	author = {{Council for International Organizations of Medical Sciences (CIOMS)}},
	urldate = {2024-05-10},
	date = {2016},
	langid = {english},
	doi = {10.56759/rgxl7405},
	file = {Council for International Organizations of Medical Sciences (CIOMS) - 2016 - International Ethical Guidelines for Health-relate.pdf:/home/maxi/Zotero/storage/5VW63ZE6/Council for International Organizations of Medical Sciences (CIOMS) - 2016 - International Ethical Guidelines for Health-relate.pdf:application/pdf},
}

@online{noauthor_httpsciomschwp-contentuploads201701web-cioms-ethicalguidelinespdf_nodate,
	title = {https://cioms.ch/wp-content/uploads/2017/01/{WEB}-{CIOMS}-{EthicalGuidelines}.pdf},
	url = {https://cioms.ch/wp-content/uploads/2017/01/WEB-CIOMS-EthicalGuidelines.pdf},
	urldate = {2024-05-10},
}

@book{noauthor_international_2016,
	location = {Geneva},
	edition = {Fourth Edition},
	title = {International Ethical Guidelines for Health-related Research Involving Humans},
	publisher = {Council for International Organizations of Medical Sciences ({CIOMS})},
	date = {2016},
}

@misc{zhdanov_implicit_2023-1,
	title = {Implicit Convolutional Kernels for Steerable {CNNs}},
	url = {http://arxiv.org/abs/2212.06096},
	doi = {10.48550/arXiv.2212.06096},
	abstract = {Steerable convolutional neural networks ({CNNs}) provide a general framework for building neural networks equivariant to translations and transformations of an origin-preserving group \$G\$, such as reflections and rotations. They rely on standard convolutions with \$G\$-steerable kernels obtained by analytically solving the group-specific equivariance constraint imposed onto the kernel space. As the solution is tailored to a particular group \$G\$, implementing a kernel basis does not generalize to other symmetry transformations, complicating the development of general group equivariant models. We propose using implicit neural representation via multi-layer perceptrons ({MLPs}) to parameterize \$G\$-steerable kernels. The resulting framework offers a simple and flexible way to implement Steerable {CNNs} and generalizes to any group \$G\$ for which a \$G\$-equivariant {MLP} can be built. We prove the effectiveness of our method on multiple tasks, including N-body simulations, point cloud classification and molecular property prediction.},
	number = {{arXiv}:2212.06096},
	publisher = {{arXiv}},
	author = {Zhdanov, Maksim and Hoffmann, Nico and Cesa, Gabriele},
	urldate = {2024-06-24},
	date = {2023-10-27},
	eprinttype = {arxiv},
	eprint = {2212.06096 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/LBPF7M4J/Zhdanov et al. - 2023 - Implicit Convolutional Kernels for Steerable CNNs.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/AHLIE97U/2212.html:text/html},
}

@misc{worrall_deep_2019,
	title = {Deep Scale-spaces: Equivariance Over Scale},
	url = {http://arxiv.org/abs/1905.11697},
	doi = {10.48550/arXiv.1905.11697},
	shorttitle = {Deep Scale-spaces},
	abstract = {We introduce deep scale-spaces ({DSS}), a generalization of convolutional neural networks, exploiting the scale symmetry structure of conventional image recognition tasks. Put plainly, the class of an image is invariant to the scale at which it is viewed. We construct scale equivariant cross-correlations based on a principled extension of convolutions, grounded in the theory of scale-spaces and semigroups. As a very basic operation, these cross-correlations can be used in almost any modern deep learning architecture in a plug-and-play manner. We demonstrate our networks on the Patch Camelyon and Cityscapes datasets, to prove their utility and perform introspective studies to further understand their properties.},
	number = {{arXiv}:1905.11697},
	publisher = {{arXiv}},
	author = {Worrall, Daniel E. and Welling, Max},
	urldate = {2024-06-24},
	date = {2019-05-28},
	eprinttype = {arxiv},
	eprint = {1905.11697 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/U2P6JLNT/Worrall and Welling - 2019 - Deep Scale-spaces Equivariance Over Scale.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/2KLI9TJS/1905.html:text/html},
}

@misc{sosnovik_scale-equivariant_2020,
	title = {Scale-Equivariant Steerable Networks},
	url = {http://arxiv.org/abs/1910.11093},
	doi = {10.48550/arXiv.1910.11093},
	abstract = {The effectiveness of Convolutional Neural Networks ({CNNs}) has been substantially attributed to their built-in property of translation equivariance. However, {CNNs} do not have embedded mechanisms to handle other types of transformations. In this work, we pay attention to scale changes, which regularly appear in various tasks due to the changing distances between the objects and the camera. First, we introduce the general theory for building scale-equivariant convolutional networks with steerable filters. We develop scale-convolution and generalize other common blocks to be scale-equivariant. We demonstrate the computational efficiency and numerical stability of the proposed method. We compare the proposed models to the previously developed methods for scale equivariance and local scale invariance. We demonstrate state-of-the-art results on {MNIST}-scale dataset and on {STL}-10 dataset in the supervised learning setting.},
	number = {{arXiv}:1910.11093},
	publisher = {{arXiv}},
	author = {Sosnovik, Ivan and Szmaja, Michał and Smeulders, Arnold},
	urldate = {2024-06-24},
	date = {2020-02-06},
	eprinttype = {arxiv},
	eprint = {1910.11093 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/4RUV3VP8/Sosnovik et al. - 2020 - Scale-Equivariant Steerable Networks.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/ZJCB84V5/1910.html:text/html},
}

@inproceedings{romero_flexconv_2021,
	title = {{FlexConv}: Continuous Kernel Convolutions With Differentiable Kernel Sizes},
	url = {https://openreview.net/forum?id=3jooF27-0Wy},
	shorttitle = {{FlexConv}},
	abstract = {When designing Convolutional Neural Networks ({CNNs}), one must select the size of the convolutional kernels before training. Recent works show {CNNs} benefit from different kernel sizes at different layers, but exploring all possible combinations is unfeasible in practice. A more efficient approach is to learn the kernel size during training. However, existing works that learn the kernel size have a limited bandwidth. These approaches scale kernels by dilation, and thus the detail they can describe is limited. In this work, we propose {FlexConv}, a novel convolutional operation with which high bandwidth convolutional kernels of learnable kernel size can be learned at a fixed parameter cost. {FlexNets} model long-term dependencies without the use of pooling, achieve state-of-the-art performance on several sequential datasets, outperform recent works with learned kernel sizes, and are competitive with much deeper {ResNets} on image benchmark datasets. Additionally, {FlexNets} can be deployed at higher resolutions than those seen during training. To avoid aliasing, we propose a novel kernel parameterization with which the frequency of the kernels can be analytically controlled. Our novel kernel parameterization shows higher descriptive power and faster convergence speed than existing parameterizations. This leads to important improvements in classification accuracy.},
	eventtitle = {International Conference on Learning Representations},
	author = {Romero, David W. and Bruintjes, Robert-Jan and Tomczak, Jakub Mikolaj and Bekkers, Erik J. and Hoogendoorn, Mark and Gemert, Jan van},
	urldate = {2024-06-24},
	date = {2021-10-06},
	langid = {english},
	file = {Full Text PDF:/home/maxi/Zotero/storage/C7QDNWRJ/Romero et al. - 2021 - FlexConv Continuous Kernel Convolutions With Diff.pdf:application/pdf},
}

@misc{finzi_practical_2021-1,
	title = {A Practical Method for Constructing Equivariant Multilayer Perceptrons for Arbitrary Matrix Groups},
	url = {http://arxiv.org/abs/2104.09459},
	doi = {10.48550/arXiv.2104.09459},
	abstract = {Symmetries and equivariance are fundamental to the generalization of neural networks on domains such as images, graphs, and point clouds. Existing work has primarily focused on a small number of groups, such as the translation, rotation, and permutation groups. In this work we provide a completely general algorithm for solving for the equivariant layers of matrix groups. In addition to recovering solutions from other works as special cases, we construct multilayer perceptrons equivariant to multiple groups that have never been tackled before, including \${\textbackslash}mathrm\{O\}(1,3)\$, \${\textbackslash}mathrm\{O\}(5)\$, \${\textbackslash}mathrm\{Sp\}(n)\$, and the Rubik's cube group. Our approach outperforms non-equivariant baselines, with applications to particle physics and dynamical systems. We release our software library to enable researchers to construct equivariant layers for arbitrary matrix groups.},
	number = {{arXiv}:2104.09459},
	publisher = {{arXiv}},
	author = {Finzi, Marc and Welling, Max and Wilson, Andrew Gordon},
	urldate = {2024-06-24},
	date = {2021-04-19},
	eprinttype = {arxiv},
	eprint = {2104.09459 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Dynamical Systems},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/9B7W3Y6N/Finzi et al. - 2021 - A Practical Method for Constructing Equivariant Mu.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/3W3KYQ57/2104.html:text/html},
}

@misc{finzi_practical_2021-2,
	title = {A Practical Method for Constructing Equivariant Multilayer Perceptrons for Arbitrary Matrix Groups},
	url = {http://arxiv.org/abs/2104.09459},
	doi = {10.48550/arXiv.2104.09459},
	abstract = {Symmetries and equivariance are fundamental to the generalization of neural networks on domains such as images, graphs, and point clouds. Existing work has primarily focused on a small number of groups, such as the translation, rotation, and permutation groups. In this work we provide a completely general algorithm for solving for the equivariant layers of matrix groups. In addition to recovering solutions from other works as special cases, we construct multilayer perceptrons equivariant to multiple groups that have never been tackled before, including \${\textbackslash}mathrm\{O\}(1,3)\$, \${\textbackslash}mathrm\{O\}(5)\$, \${\textbackslash}mathrm\{Sp\}(n)\$, and the Rubik's cube group. Our approach outperforms non-equivariant baselines, with applications to particle physics and dynamical systems. We release our software library to enable researchers to construct equivariant layers for arbitrary matrix groups.},
	number = {{arXiv}:2104.09459},
	publisher = {{arXiv}},
	author = {Finzi, Marc and Welling, Max and Wilson, Andrew Gordon},
	urldate = {2024-06-24},
	date = {2021-04-19},
	eprinttype = {arxiv},
	eprint = {2104.09459 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Dynamical Systems},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/RACGGR9I/Finzi et al. - 2021 - A Practical Method for Constructing Equivariant Mu.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/B9RUBUIK/2104.html:text/html},
}

@misc{knigge_modelling_2023,
	title = {Modelling Long Range Dependencies in \$N\$D: From Task-Specific to a General Purpose {CNN}},
	url = {http://arxiv.org/abs/2301.10540},
	doi = {10.48550/arXiv.2301.10540},
	shorttitle = {Modelling Long Range Dependencies in \$N\$D},
	abstract = {Performant Convolutional Neural Network ({CNN}) architectures must be tailored to specific tasks in order to consider the length, resolution, and dimensionality of the input data. In this work, we tackle the need for problem-specific {CNN} architectures. We present the Continuous Convolutional Neural Network ({CCNN}): a single {CNN} able to process data of arbitrary resolution, dimensionality and length without any structural changes. Its key component are its continuous convolutional kernels which model long-range dependencies at every layer, and thus remove the need of current {CNN} architectures for task-dependent downsampling and depths. We showcase the generality of our method by using the same architecture for tasks on sequential (\$1\{{\textbackslash}rm D\}\$), visual (\$2\{{\textbackslash}rm D\}\$) and point-cloud (\$3\{{\textbackslash}rm D\}\$) data. Our {CCNN} matches and often outperforms the current state-of-the-art across all tasks considered.},
	number = {{arXiv}:2301.10540},
	publisher = {{arXiv}},
	author = {Knigge, David M. and Romero, David W. and Gu, Albert and Gavves, Efstratios and Bekkers, Erik J. and Tomczak, Jakub M. and Hoogendoorn, Mark and Sonke, Jan-Jakob},
	urldate = {2024-06-24},
	date = {2023-04-16},
	eprinttype = {arxiv},
	eprint = {2301.10540 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/CPI5L8Z5/Knigge et al. - 2023 - Modelling Long Range Dependencies in \$N\$D From Ta.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/8J9LJ5NR/2301.html:text/html},
}

@misc{finzi_generalizing_2020,
	title = {Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data},
	url = {http://arxiv.org/abs/2002.12880},
	doi = {10.48550/arXiv.2002.12880},
	abstract = {The translation equivariance of convolutional layers enables convolutional neural networks to generalize well on image problems. While translation equivariance provides a powerful inductive bias for images, we often additionally desire equivariance to other transformations, such as rotations, especially for non-image data. We propose a general method to construct a convolutional layer that is equivariant to transformations from any specified Lie group with a surjective exponential map. Incorporating equivariance to a new group requires implementing only the group exponential and logarithm maps, enabling rapid prototyping. Showcasing the simplicity and generality of our method, we apply the same model architecture to images, ball-and-stick molecular data, and Hamiltonian dynamical systems. For Hamiltonian systems, the equivariance of our models is especially impactful, leading to exact conservation of linear and angular momentum.},
	number = {{arXiv}:2002.12880},
	publisher = {{arXiv}},
	author = {Finzi, Marc and Stanton, Samuel and Izmailov, Pavel and Wilson, Andrew Gordon},
	urldate = {2024-06-24},
	date = {2020-09-24},
	eprinttype = {arxiv},
	eprint = {2002.12880 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/A6PZAAYR/Finzi et al. - 2020 - Generalizing Convolutional Neural Networks for Equ.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/7BYU4IQT/2002.html:text/html},
}

@misc{cohen_spherical_2018,
	title = {Spherical {CNNs}},
	url = {http://arxiv.org/abs/1801.10130},
	doi = {10.48550/arXiv.1801.10130},
	abstract = {Convolutional Neural Networks ({CNNs}) have become the method of choice for learning problems involving 2D planar images. However, a number of problems of recent interest have created a demand for models that can analyze spherical images. Examples include omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modelling. A naive application of convolutional networks to a planar projection of the spherical signal is destined to fail, because the space-varying distortions introduced by such a projection will make translational weight sharing ineffective. In this paper we introduce the building blocks for constructing spherical {CNNs}. We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant. The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute it efficiently using a generalized (non-commutative) Fast Fourier Transform ({FFT}) algorithm. We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical {CNNs} applied to 3D model recognition and atomization energy regression.},
	number = {{arXiv}:1801.10130},
	publisher = {{arXiv}},
	author = {Cohen, Taco S. and Geiger, Mario and Koehler, Jonas and Welling, Max},
	urldate = {2024-06-24},
	date = {2018-02-25},
	eprinttype = {arxiv},
	eprint = {1801.10130 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/JVZIEVGA/Cohen et al. - 2018 - Spherical CNNs.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/MEBV7RTV/1801.html:text/html},
}

@misc{van_der_pol_mdp_2021,
	title = {{MDP} Homomorphic Networks: Group Symmetries in Reinforcement Learning},
	url = {http://arxiv.org/abs/2006.16908},
	doi = {10.48550/arXiv.2006.16908},
	shorttitle = {{MDP} Homomorphic Networks},
	abstract = {This paper introduces {MDP} homomorphic networks for deep reinforcement learning. {MDP} homomorphic networks are neural networks that are equivariant under symmetries in the joint state-action space of an {MDP}. Current approaches to deep reinforcement learning do not usually exploit knowledge about such structure. By building this prior knowledge into policy and value networks using an equivariance constraint, we can reduce the size of the solution space. We specifically focus on group-structured symmetries (invertible transformations). Additionally, we introduce an easy method for constructing equivariant network layers numerically, so the system designer need not solve the constraints by hand, as is typically done. We construct {MDP} homomorphic {MLPs} and {CNNs} that are equivariant under either a group of reflections or rotations. We show that such networks converge faster than unstructured baselines on {CartPole}, a grid world and Pong.},
	number = {{arXiv}:2006.16908},
	publisher = {{arXiv}},
	author = {van der Pol, Elise and Worrall, Daniel E. and van Hoof, Herke and Oliehoek, Frans A. and Welling, Max},
	urldate = {2024-06-24},
	date = {2021-01-20},
	eprinttype = {arxiv},
	eprint = {2006.16908 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/EJ89KTIT/van der Pol et al. - 2021 - MDP Homomorphic Networks Group Symmetries in Rein.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/6PHS8HBJ/2006.html:text/html},
}

@article{bui_dax-net_2024,
	title = {{DAX}-Net: A dual-branch dual-task adaptive cross-weight feature fusion network for robust multi-class cancer classification in pathology images},
	volume = {248},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260724001081},
	doi = {10.1016/j.cmpb.2024.108112},
	shorttitle = {{DAX}-Net},
	abstract = {Background and Objective
Multi-class cancer classification has been extensively studied in digital and computational pathology due to its importance in clinical decision-making. Numerous computational tools have been proposed for various types of cancer classification. Many of them are built based on convolutional neural networks. Recently, Transformer-style networks have shown to be effective for cancer classification. Herein, we present a hybrid design that leverages both convolutional neural networks and transformer architecture to obtain superior performance in cancer classification.
Methods
We propose a dual-branch dual-task adaptive cross-weight feature fusion network, called {DAX}-Net, which exploits heterogeneous feature representations from the convolutional neural network and Transformer network, adaptively combines them to boost their representation power, and conducts cancer classification as categorical classification and ordinal classification. For an efficient and effective optimization of the proposed model, we introduce two loss functions that are tailored to the two classification tasks.
Results
To evaluate the proposed method, we employed colorectal and prostate cancer datasets, of which each contains both in-domain and out-of-domain test sets. For colorectal cancer, the proposed method obtained an accuracy of 88.4\%, a quadratic kappa score of 0.945, and an F1 score of 0.831 for the in-domain test set, and 84.4\%, 0.910, and 0.768 for the out-of-domain test set. For prostate cancer, it achieved an accuracy of 71.6\%, a kappa score of 0.635, and an F1 score of 0.655 for the in-domain test set, 79.2\% accuracy, 0.721 kappa score, and 0.686 F1 score for the first out-of-domain test set, and 58.1\% accuracy, 0.564 kappa score, and 0.493 F1 score for the second out-of-domain test set. It is worth noting that the performance of the proposed method outperformed other competitors by significant margins, in particular, with respect to the out-of-domain test sets.
Conclusions
The experimental results demonstrate that the proposed method is not only accurate but also robust to varying conditions of the test sets in comparison to several, related methods. These results suggest that the proposed method can facilitate automated cancer classification in various clinical settings.},
	pages = {108112},
	journaltitle = {Computer Methods and Programs in Biomedicine},
	shortjournal = {Computer Methods and Programs in Biomedicine},
	author = {Bui, Doanh C. and Song, Boram and Kim, Kyungeun and Kwak, Jin Tae},
	urldate = {2024-06-26},
	date = {2024-05-01},
	keywords = {Cancer classification, {CNN}, Feature fusion, Hybrid model, Multi-task learning, Transformer},
	file = {ScienceDirect Snapshot:/home/maxi/Zotero/storage/RUHWUL66/S0169260724001081.html:text/html},
}

@misc{omahony_color_2024,
	title = {Color Equivariant Network},
	url = {http://arxiv.org/abs/2406.09588},
	doi = {10.48550/arXiv.2406.09588},
	abstract = {Group equivariant convolutional neural networks have been designed for a variety of geometric transformations from 2D and 3D rotation groups, to semi-groups such as scale. Despite the improved interpretability, accuracy and generalizability afforded by these architectures, group equivariant networks have seen limited application in the context of perceptual quantities such as hue and saturation, even though their variation can lead to significant reductions in classification performance. In this paper, we introduce convolutional neural networks equivariant to variations in hue and saturation by design. To achieve this, we leverage the observation that hue and saturation transformations can be identified with the 2D rotation and 1D translation groups respectively. Our hue-, saturation-, and fully color-equivariant networks achieve equivariance to these perceptual transformations without an increase in network parameters. We demonstrate the utility of our networks on synthetic and real world datasets where color and lighting variations are commonplace.},
	number = {{arXiv}:2406.09588},
	publisher = {{arXiv}},
	author = {O'Mahony, Felix and Yang, Yulong and Allen-Blanchette, Christine},
	urldate = {2024-08-10},
	date = {2024-06-13},
	eprinttype = {arxiv},
	eprint = {2406.09588 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/ETVY6T8P/O'Mahony et al. - 2024 - Color Equivariant Network.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/PG4CQP3H/2406.html:text/html},
}

@misc{sun_empowering_2023,
	title = {Empowering Networks With Scale and Rotation Equivariance Using A Similarity Convolution},
	url = {http://arxiv.org/abs/2303.00326},
	doi = {10.48550/arXiv.2303.00326},
	abstract = {The translational equivariant nature of Convolutional Neural Networks ({CNNs}) is a reason for its great success in computer vision. However, networks do not enjoy more general equivariance properties such as rotation or scaling, ultimately limiting their generalization performance. To address this limitation, we devise a method that endows {CNNs} with simultaneous equivariance with respect to translation, rotation, and scaling. Our approach defines a convolution-like operation and ensures equivariance based on our proposed scalable Fourier-Argand representation. The method maintains similar efficiency as a traditional network and hardly introduces any additional learnable parameters, since it does not face the computational issue that often occurs in group-convolution operators. We validate the efficacy of our approach in the image classification task, demonstrating its robustness and the generalization ability to both scaled and rotated inputs.},
	number = {{arXiv}:2303.00326},
	publisher = {{arXiv}},
	author = {Sun, Zikai and Blu, Thierry},
	urldate = {2024-08-10},
	date = {2023-03-01},
	eprinttype = {arxiv},
	eprint = {2303.00326 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/J4JL9BTZ/Sun and Blu - 2023 - Empowering Networks With Scale and Rotation Equiva.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/XAWT3INP/2303.html:text/html},
}

@misc{worrall_deep_2019-1,
	title = {Deep Scale-spaces: Equivariance Over Scale},
	url = {http://arxiv.org/abs/1905.11697},
	doi = {10.48550/arXiv.1905.11697},
	shorttitle = {Deep Scale-spaces},
	abstract = {We introduce deep scale-spaces ({DSS}), a generalization of convolutional neural networks, exploiting the scale symmetry structure of conventional image recognition tasks. Put plainly, the class of an image is invariant to the scale at which it is viewed. We construct scale equivariant cross-correlations based on a principled extension of convolutions, grounded in the theory of scale-spaces and semigroups. As a very basic operation, these cross-correlations can be used in almost any modern deep learning architecture in a plug-and-play manner. We demonstrate our networks on the Patch Camelyon and Cityscapes datasets, to prove their utility and perform introspective studies to further understand their properties.},
	number = {{arXiv}:1905.11697},
	publisher = {{arXiv}},
	author = {Worrall, Daniel E. and Welling, Max},
	urldate = {2024-08-10},
	date = {2019-05-28},
	eprinttype = {arxiv},
	eprint = {1905.11697 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/PQ6AJRDG/Worrall and Welling - 2019 - Deep Scale-spaces Equivariance Over Scale.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/ZWRVZIF5/1905.html:text/html},
}

@misc{romero_attentive_2020,
	title = {Attentive Group Equivariant Convolutional Networks},
	url = {http://arxiv.org/abs/2002.03830},
	doi = {10.48550/arXiv.2002.03830},
	abstract = {Although group convolutional networks are able to learn powerful representations based on symmetry patterns, they lack explicit means to learn meaningful relationships among them (e.g., relative positions and poses). In this paper, we present attentive group equivariant convolutions, a generalization of the group convolution, in which attention is applied during the course of convolution to accentuate meaningful symmetry combinations and suppress non-plausible, misleading ones. We indicate that prior work on visual attention can be described as special cases of our proposed framework and show empirically that our attentive group equivariant convolutional networks consistently outperform conventional group convolutional networks on benchmark image datasets. Simultaneously, we provide interpretability to the learned concepts through the visualization of equivariant attention maps.},
	number = {{arXiv}:2002.03830},
	publisher = {{arXiv}},
	author = {Romero, David W. and Bekkers, Erik J. and Tomczak, Jakub M. and Hoogendoorn, Mark},
	urldate = {2024-08-28},
	date = {2020-06-30},
	eprinttype = {arxiv},
	eprint = {2002.03830 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/GM6FMEQV/Romero et al. - 2020 - Attentive Group Equivariant Convolutional Networks.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/MY52AMDS/2002.html:text/html},
}

@misc{lengyel_color_2023,
	title = {Color Equivariant Convolutional Networks},
	url = {http://arxiv.org/abs/2310.19368},
	abstract = {Color is a crucial visual cue readily exploited by Convolutional Neural Networks ({CNNs}) for object recognition. However, {CNNs} struggle if there is data imbalance between color variations introduced by accidental recording conditions. Color invariance addresses this issue but does so at the cost of removing all color information, which sacrifices discriminative power. In this paper, we propose Color Equivariant Convolutions ({CEConvs}), a novel deep learning building block that enables shape feature sharing across the color spectrum while retaining important color information. We extend the notion of equivariance from geometric to photometric transformations by incorporating parameter sharing over hue-shifts in a neural network. We demonstrate the benefits of {CEConvs} in terms of downstream performance to various tasks and improved robustness to color changes, including train-test distribution shifts. Our approach can be seamlessly integrated into existing architectures, such as {ResNets}, and offers a promising solution for addressing color-based domain shifts in {CNNs}.},
	number = {{arXiv}:2310.19368},
	publisher = {{arXiv}},
	author = {Lengyel, Attila and Strafforello, Ombretta and Bruintjes, Robert-Jan and Gielisse, Alexander and van Gemert, Jan},
	urldate = {2024-09-07},
	date = {2023-10-30},
	eprinttype = {arxiv},
	eprint = {2310.19368 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/maxi/Zotero/storage/7KPHGWSH/Lengyel et al. - 2023 - Color Equivariant Convolutional Networks.pdf:application/pdf;arXiv.org Snapshot:/home/maxi/Zotero/storage/TTLM5VPR/2310.html:text/html},
}

@article{pardo_c_atlas_2017,
	title = {Atlas de mortalidad por cáncer en Colombia},
	volume = {1},
	url = {https://www.ins.gov.co/TyS/programas-de-calidad/Documentos%20Programa%20EEDDCARIO/ATLAS_de_Mortalidad_por_cancer_en_Colombia.pdf},
	pages = {124},
	issue = {Cuarta edición},
	journaltitle = {Instituto Nacional de Cancerología},
	author = {{Pardo C} and {de Vries E} and {Buitrago L} and {Gamboa O}},
	date = {2017},
	file = {PDF:/home/maxi/Zotero/storage/CVZBZRDY/Pardo C et al. - 2017 - Atlas de mortalidad por cáncer en Colombia.pdf:application/pdf},
}

@article{rosell_variabilidad_nodate,
	title = {Variabilidad en el diagnóstico, tratamiento y pronóstico del cáncer vesical en españa. análisis según el área geográfica y la categoría de hospital.},
	author = {Rosell, Lluís Cecchini},
	langid = {spanish},
	file = {PDF:/home/maxi/Zotero/storage/PU7V2GNC/Rosell - Variabilidad en el diagnóstico, tratamiento y pronóstico del cáncer vesical en españa. análisis segú.pdf:application/pdf},
}

@thesis{martinez_mora_diseno_2022,
	title = {Diseño y desarrollo de un sistema de gradación de patrones cancerosos en imágenes histopatológicas de próstata utilizando algoritmos de deep learning que tengan en cuenta la incertidumbre y variabilidad inter-patólogo durante el entrenamiento},
	rights = {Reconocimiento - No comercial - Sin obra derivada (by-nc-nd)},
	url = {https://riunet.upv.es/handle/10251/181899},
	abstract = {[{ES}] El cáncer de próstata es a nivel mundial el segundo tipo de cáncer con mayor prevalencia. En 2018 se diagnosticaron 1.3 millones de pacientes y se estima que el número de casos anuales nuevos aumente en un 40.2\% en 2030. Esta patología es diagnosticada a partir del análisis visual de biopsias por medio del patólogo y la clasificación de la diferenciación del tejido según la escala Gleason. Esta escala va de 3 a 5, siendo inversamente proporcional al grado de diferenciación. Este proceso diagnóstico es una tarea que consume grandes cantidades de tiempo, y sufre de una elevada variabilidad entre patólogos. Para reducir la carga de trabajo y aumentar el nivel de objetividad, en los últimos años se han propuesto sistemas de ayuda al diagnóstico basados en algoritmos de deep learning y, en concreto, redes neuronales convoluciones. A pesar de los prometedores resultados obtenidos por estos sistemas, las técnicas punteras aún se ven limitadas, entre otros factores, por el sesgo introducido en la anotación durante el entrenamiento. 
Por ello, el objetivo de este {TFG} es el desarrollo de modelos de deep learning robustos a la variabilidad entre patólogos durante el entrenamiento con tal de mejorar la capacidad de generalización. En esta línea, se pretende utilizar funciones de pérdida basadas en el estadístico cuadrático de Cohen, y en suavizado de etiquetas. Asimismo, se tratará de optimizar las arquitecturas de redes neuronales convolucionales utilizadas en el estado del arte, incluyendo bloques de atención. Con tal de validar la mejora en la capacidad de generalización, estos métodos serán entrenados y testeados en distintas bases de datos, con etiquetas de referencia dadas por distintos patólogos.},
	institution = {Universitat Politècnica de València},
	type = {Proyecto/Trabajo fin de carrera/grado},
	author = {Martínez Mora, Marta},
	urldate = {2024-09-16},
	date = {2022-04-07},
	note = {Accepted: 2022-04-07T08:52:06Z},
	file = {Full Text PDF:/home/maxi/Zotero/storage/HKA5QKUB/Martínez Mora - 2022 - Diseño y desarrollo de un sistema de gradación de patrones cancerosos en imágenes histopatológicas d.pdf:application/pdf},
}

@article{wang_managing_2012,
	title = {Managing and Querying Whole Slide Images},
	volume = {8319},
	issn = {1996-756X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3405921/},
	abstract = {High-resolution pathology images provide rich information about the morphological and functional characteristics of biological systems, and are transforming the field of pathology into a new era. To facilitate the use of digital pathology imaging for biomedical research and clinical diagnosis, it is essential to manage and query both whole slide images ({WSI}) and analytical results generated from images, such as annotations made by humans and computed features and classifications made by computer algorithms. There are unique requirements on modeling, managing and querying whole slide images, including compatibility with standards, scalability, support of image queries at multiple granularities, and support of integrated queries between images and derived results from the images. In this paper, we present our work on developing the Pathology Image Database System ({PIDB}), which is a standard oriented image database to support retrieval of images, tiles, regions and analytical results, image visualization and experiment management through a unified interface and architecture. The system is deployed for managing and querying whole slide images for In Silico brain tumor studies at Emory University. {PIDB} is generic and open source, and can be easily used to support other biomedical research projects. It has the potential to be integrated into a Picture Archiving and Communications System ({PACS}) with powerful query capabilities to support pathology imaging.},
	pages = {83190J},
	journaltitle = {Proceedings of {SPIE}},
	shortjournal = {Proc {SPIE}},
	author = {Wang, Fusheng and Oh, Tae W. and Vergara-Niedermayr, Cristobal and Kurc, Tahsin and Saltz, Joel},
	urldate = {2024-09-16},
	date = {2012-02-16},
	pmid = {22844574},
	pmcid = {PMC3405921},
	file = {PubMed Central Full Text PDF:/home/maxi/Zotero/storage/PM6ECHB9/Wang et al. - 2012 - Managing and Querying Whole Slide Images.pdf:application/pdf},
}

@article{lindman_annotations_2019,
	title = {Annotations, Ontologies, and Whole Slide Images – Development of an Annotated Ontology-Driven Whole Slide Image Library of Normal and Abnormal Human Tissue},
	volume = {10},
	issn = {2229-5089},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6669998/},
	doi = {10.4103/jpi.jpi_81_18},
	abstract = {Objective:
Digital pathology is today a widely used technology, and the digitalization of microscopic slides into whole slide images ({WSIs}) allows the use of machine learning algorithms as a tool in the diagnostic process. In recent years, “deep learning” algorithms for image analysis have been applied to digital pathology with great success. The training of these algorithms requires a large volume of high-quality images and image annotations. These large image collections are a potent source of information, and to use and share the information, standardization of the content through a consistent terminology is essential. The aim of this project was to develop a pilot dataset of exhaustive annotated {WSI} of normal and abnormal human tissue and link the annotations to appropriate ontological information.

Materials and Methods:
Several biomedical ontologies and controlled vocabularies were investigated with the aim of selecting the most suitable ontology for this project. The selection criteria required an ontology that covered anatomical locations, histological subcompartments, histopathologic diagnoses, histopathologic terms, and generic terms such as normal, abnormal, and artifact. {WSIs} of normal and abnormal tissue from 50 colon resections and 69 skin excisions, diagnosed 2015-2016 at the Department of Clinical Pathology in Linköping, were randomly collected. These images were manually and exhaustively annotated at the level of major subcompartments, including normal or abnormal findings and artifacts.

Results:
Systemized nomenclature of medicine clinical terms ({SNOMED} {CT}) was chosen, and the annotations were linked to its codes and terms. Two hundred {WSI} were collected and annotated, resulting in 17,497 annotations, covering a total area of 302.19 cm2, equivalent to 107,7 gigapixels. Ninety-five unique {SNOMED} {CT} codes were used. The time taken to annotate a {WSI} varied from 45 s to over 360 min, a total time of approximately 360 h.

Conclusion:
This work resulted in a dataset of 200 exhaustive annotated {WSIs} of normal and abnormal tissue from the colon and skin, and it has informed plans to build a comprehensive library of annotated {WSIs}. {SNOMED} {CT} was found to be the best ontology for annotation labeling. This project also demonstrates the need for future development of annotation tools in order to make the annotation process more efficient.},
	pages = {22},
	journaltitle = {Journal of Pathology Informatics},
	shortjournal = {J Pathol Inform},
	author = {Lindman, Karin and Rose, Jerómino F. and Lindvall, Martin and Lundström, Claes and Treanor, Darren},
	urldate = {2024-09-16},
	date = {2019-07-23},
	pmid = {31523480},
	pmcid = {PMC6669998},
	file = {PubMed Central Full Text PDF:/home/maxi/Zotero/storage/AXYYNGWD/Lindman et al. - 2019 - Annotations, Ontologies, and Whole Slide Images – Development of an Annotated Ontology-Driven Whole.pdf:application/pdf},
}
